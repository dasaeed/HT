{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.special import gammaln, digamma\n",
    "eps = 1e-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9,  6,  5,  8, 10,  9,  6,  5,  6, 10,  6,  5,  6,  5, 10,  5,\n",
       "        5,  9,  6,  6,  9,  6,  5,  6,  8,  6, 10,  6,  2,  5,  3,  9, 10,\n",
       "        5,  5,  5,  7,  5, 10,  2,  9,  9,  6,  6,  9,  5,  5,  6,  6,  5,\n",
       "        9,  5,  8,  5,  6,  6])"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "V = 10\n",
    "N = 50\n",
    "M = npr.poisson(50, size=N)\n",
    "eta0 = 0.1\n",
    "alpha0 = 0.1\n",
    "\n",
    "rs = npr.RandomState(npr.randint(0, 100))\n",
    "beta = rs.dirichlet(np.full(V, eta0), size=K)\n",
    "theta = rs.dirichlet(np.full(K, alpha0), size=N)\n",
    "X = []\n",
    "i = 0\n",
    "x_i = np.zeros(M[i], dtype=int)\n",
    "for j in range(M[i]):\n",
    "    z_ij = rs.choice(K, p=theta[i])\n",
    "    x_ij = rs.choice(V, p=beta[z_ij]) + 1\n",
    "    x_i[j] = x_ij\n",
    "# for i in range(N):\n",
    "#     x_i = np.zeros(M[i], dtype=int)\n",
    "#     for j in range(M[i]):\n",
    "#         z_ij = rs.choice(K, p=theta[i])\n",
    "#         x_ij = rs.choice(V, p=beta[z_ij])\n",
    "#         x_i[j] = x_ij\n",
    "x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_LDA(K, V, N, M, eta0=0.1, alpha0=0.5, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    beta = rs.dirichlet(np.full(V, eta0), size=K)\n",
    "    theta = rs.dirichlet(np.full(K, alpha0), size=N)\n",
    "    X = []\n",
    "    for i in range(N):\n",
    "        x_i = np.zeros(M[i], dtype=int)\n",
    "        for j in range(M[i]):\n",
    "            z_ij = rs.choice(K, p=theta[i])\n",
    "            x_ij = rs.choice(V, p=beta[z_ij])\n",
    "            x_i[j] = x_ij\n",
    "        X.append(x_i)\n",
    "    return X\n",
    "\n",
    "def init_variational_params(X, K, V):\n",
    "    N = len(X)\n",
    "    Ms = np.array([len(x_i) for x_i in X])\n",
    "    lambd = npr.uniform(low=0.01, high=1.0, size=(K, V))\n",
    "    gamma = np.ones((N, K))\n",
    "    phi = []\n",
    "    for M_i in Ms:\n",
    "        phi_i = np.ones((M_i, K))\n",
    "        phi_i = phi_i / K\n",
    "        phi.append(phi_i)\n",
    "    return lambd, gamma, phi\n",
    "\n",
    "rs = npr.RandomState(0)\n",
    "eta0 = 0.1\n",
    "alpha0 = 0.5\n",
    "K = 5\n",
    "V = 500\n",
    "N = 10\n",
    "M = npr.poisson(10, size=N)\n",
    "X = simulate_LDA(K, V, N, M, eta0, alpha0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dir(x, alpha):\n",
    "    return digamma(np.sum(alpha)) - digamma(alpha) + np.log(x + 1e-10)\n",
    "\n",
    "def score_cat(z, phi):\n",
    "    return z / phi\n",
    "\n",
    "def sample_variational_params(var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    K, V = lambd.shape\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    \n",
    "    beta = np.zeros((K, V))\n",
    "    for k in range(K):\n",
    "        beta[k] = npr.dirichlet(lambd[k])\n",
    "    \n",
    "    theta = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        theta[i] = npr.dirichlet(gamma[i])\n",
    "\n",
    "    z = []\n",
    "    for i in range(N):\n",
    "        z_i = np.zeros(Ms[i], dtype=int)\n",
    "        for j in range(Ms[i]):\n",
    "            z_i[j] = npr.choice(K, p=phi[i][j])\n",
    "        z.append(z_i)\n",
    "    \n",
    "    return beta, theta, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir(x, alpha):\n",
    "    return gammaln(np.sum(alpha)) - np.sum(gammaln(alpha)) + np.sum((alpha-1) * np.log(x + 1e-10))\n",
    "\n",
    "def log_variational_dist(latent_params, var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    beta, theta, z = latent_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "\n",
    "    log_q = 0.0\n",
    "    for k in range(K):\n",
    "        log_q += log_dir(beta[k], lambd[k])\n",
    "\n",
    "    for i in range(N):\n",
    "        log_q += log_dir(theta[i], gamma[i])\n",
    "        for j in range(Ms[i]):\n",
    "            for k in range(K):\n",
    "                log_q += float(z[i][j] == k) * np.log(phi[i][j, k] + eps)\n",
    "    return log_q\n",
    "\n",
    "def log_joint_prob(latent_params, X):\n",
    "    beta, theta, z = latent_params\n",
    "    K, V = beta.shape\n",
    "    N = theta.shape[0]\n",
    "    Ms = np.array([len(z[i]) for i in range(len(z))])\n",
    "\n",
    "    log_p_beta = 0.0\n",
    "    for k in range(K):\n",
    "        log_p_beta += log_dir(beta[k], np.full(V, eta))\n",
    "\n",
    "    log_p_theta = 0.0\n",
    "    log_p_z = 0.0\n",
    "    log_p_x = 0.0\n",
    "    for i in range(N):\n",
    "        log_p_theta += log_dir(theta[i], np.full(K, alpha))\n",
    "        for j in range(Ms[i]):\n",
    "            log_p_z += np.log(theta[i, z[i][j]])\n",
    "            log_p_x += np.log(beta[z[i][j], X[i][j]])\n",
    "    return log_p_beta + log_p_theta + log_p_z + log_p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_variational_dist(latent_params, var_params):\n",
    "    beta, theta, z = latent_params\n",
    "    lambd, gamma, phi = var_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    grad_lambda = np.zeros(V)\n",
    "    grad_gamma = np.zeros(K)\n",
    "    grad_phi = np.zeros(K)\n",
    "\n",
    "    for k in range(K):\n",
    "        grad_lambda_k = np.zeros(V)\n",
    "        for v in range(V):\n",
    "            assert beta[k, v] >= 0\n",
    "            grad_lambda_k[v] = digamma(np.sum(lambd[k])) - digamma(lambd[k, v]) + np.log(beta[k, v] + 1e-10)\n",
    "        grad_lambda += grad_lambda_k\n",
    "    \n",
    "    for i in range(N):\n",
    "        grad_gamma_i = np.zeros(K)\n",
    "        for k in range(K):\n",
    "            assert theta[i, k] > 0\n",
    "            grad_gamma_i[k] = digamma(np.sum(gamma[i])) - digamma(gamma[i, k]) + np.log(theta[i, k] + 1e-10)\n",
    "        grad_gamma += grad_gamma_i\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(Ms[i]):\n",
    "            grad_phi_ij = np.zeros(K)\n",
    "            for k in range(K):\n",
    "                grad_phi_ij[k] = float(z[i][j] == k) / phi[i][j, k]\n",
    "            grad_phi += grad_phi_ij\n",
    "    return grad_lambda, grad_gamma, grad_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "S = 20\n",
    "eta = 0.0000001\n",
    "eps = 1e-6\n",
    "lr_lambda = lr_gamma = lr_phi = eta\n",
    "G_lambda = np.zeros(V)\n",
    "G_gamma = np.zeros(K)\n",
    "G_phi = np.zeros(K)\n",
    "\n",
    "lambd, gamma, phi = init_variational_params(X, K, V)\n",
    "grad_lambda = np.zeros(V)\n",
    "grad_gamma = np.zeros(K)\n",
    "grad_phi = np.zeros(K)\n",
    "\n",
    "for t in range(1000):\n",
    "    for s in range(S):\n",
    "        beta_s, theta_s, z_s = sample_variational_params((lambd, gamma, phi))\n",
    "        grad_lambda_s, grad_gamma_s, grad_phi_s = score_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        log_p, log_q = log_joint_prob((beta_s, theta_s, z_s), X), log_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        grad_lambda += grad_lambda_s * (log_p - log_q)\n",
    "        grad_gamma += grad_gamma_s * (log_p - log_q)\n",
    "        grad_phi += grad_phi_s * (log_p - log_q)\n",
    "    grad_lambda /= S\n",
    "    grad_gamma /= S\n",
    "    grad_phi /= S\n",
    "\n",
    "    G_lambda += np.square(grad_lambda)\n",
    "    G_gamma += np.square(grad_gamma)\n",
    "    G_phi += np.square(grad_phi)\n",
    "\n",
    "    lr_lambda = eta / np.sqrt(G_lambda + eps)\n",
    "    lr_gamma = eta / np.sqrt(G_gamma + eps)\n",
    "    lr_phi = eta / np.sqrt(G_phi + eta)\n",
    "\n",
    "    lambd += lr_lambda * grad_lambda\n",
    "    lambd = np.maximum(lambd, 1e-5)\n",
    "    gamma += lr_gamma * grad_gamma\n",
    "    gamma = np.maximum(gamma, 1e-5)\n",
    "    for i in range(N):\n",
    "        phi[i] += lr_phi * grad_phi\n",
    "        phi[i] = phi[i] / phi[i].sum(axis=1, keepdims=True)\n",
    "    if t % 100 == 0:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModeResult(mode=array([0.02894835, 0.58892686, 0.13111334, 0.25840583, 0.24143926,\n",
       "       0.16777638, 0.09798775, 0.29752736, 0.01899156, 0.25634053,\n",
       "       0.38678771, 0.15177852, 0.06888556, 0.36558001, 0.23014562,\n",
       "       0.01411915, 0.07472059, 0.14255709, 0.35967489, 0.17878896,\n",
       "       0.0626343 , 0.01070142, 0.03588282, 0.05943561, 0.13892424,\n",
       "       0.30845921, 0.16994307, 0.13341858, 0.03092116, 0.33621839,\n",
       "       0.40971375, 0.01507124, 0.7200196 , 0.1445776 , 0.10218153,\n",
       "       0.59500313, 0.18863063, 0.39598547, 0.21616192, 0.21537945,\n",
       "       0.03679043, 0.19236899, 0.09426296, 0.23378499, 0.04341779,\n",
       "       0.03446724, 0.02516611, 0.59384448, 0.3696326 , 0.14679525,\n",
       "       0.07819982, 0.38616314, 0.1200598 , 0.11410448, 0.29588956,\n",
       "       0.27239536, 0.01062785, 0.1029726 , 0.21183283, 0.09150654,\n",
       "       0.15005094, 0.02184367, 0.08930682, 0.22849604, 0.2144991 ,\n",
       "       0.32954936, 0.03748791, 0.01320275, 0.19205902, 0.2155242 ,\n",
       "       0.1572662 , 0.56371885, 0.26965703, 0.21405914, 0.54325645,\n",
       "       0.07150655, 0.12134778, 0.01206542, 0.16130941, 0.45172895,\n",
       "       0.08327518, 0.01424445, 0.13472812, 0.21877905, 0.25987138,\n",
       "       0.26317199, 0.4117272 , 0.41522694, 0.07452532, 0.38402762,\n",
       "       0.22742593, 0.11181512, 0.17244931, 0.01961805, 0.06496801,\n",
       "       0.0515337 , 0.24375783, 0.11794315, 0.2202259 , 0.37014248,\n",
       "       0.15519138, 0.08117653, 0.35368298, 0.09014839, 0.07272379,\n",
       "       0.04189197, 0.22791867, 0.22959003, 0.08218589, 0.37482136,\n",
       "       0.11683068, 0.28992941, 0.20536292, 0.06792863, 0.19318059,\n",
       "       0.05444754, 0.15052466, 0.23611452, 0.05401972, 0.372244  ,\n",
       "       0.40273268, 0.08794043, 0.36156609, 0.35258484, 0.01961528,\n",
       "       0.03576921, 0.40438828, 0.01744328, 0.14626186, 0.0830481 ,\n",
       "       0.16893512, 0.02916678, 0.63729037, 0.02385685, 0.01144788,\n",
       "       0.08386149, 0.09030737, 0.02838076, 0.11432877, 0.05566265,\n",
       "       0.09708059, 0.22879628, 0.24127294, 0.64100155, 0.29768566,\n",
       "       0.16958358, 0.08179637, 0.0502938 , 0.08015777, 0.55068106,\n",
       "       0.03561636, 0.04624529, 0.25707753, 0.10132783, 0.2718133 ,\n",
       "       0.04800172, 0.0825091 , 0.1419429 , 0.22491442, 0.31735275,\n",
       "       0.52104523, 0.03528201, 0.18540532, 0.02562274, 0.26840277,\n",
       "       0.16181925, 0.19798706, 0.6669971 , 0.22663269, 0.26462653,\n",
       "       0.22508916, 0.50734214, 0.4314982 , 0.2068896 , 0.05259276,\n",
       "       0.02737136, 0.20816932, 0.10308549, 0.07411542, 0.09072693,\n",
       "       0.16445835, 0.11525494, 0.04089931, 0.21564808, 0.19430455,\n",
       "       0.28889789, 0.02852213, 0.19015316, 0.01512853, 0.4613436 ,\n",
       "       0.24745248, 0.2967972 , 0.30577417, 0.13887617, 0.28674447,\n",
       "       0.07182674, 0.10055156, 0.27284225, 0.17212909, 0.14982359,\n",
       "       0.04865213, 0.37167358, 0.26222552, 0.17184417, 0.03950012,\n",
       "       0.41229555, 0.12549878, 0.13858066, 0.09572851, 0.24962238,\n",
       "       0.17584082, 0.0263785 , 0.13309977, 0.33398678, 0.21870589,\n",
       "       0.1278763 , 0.05756796, 0.15764961, 0.48235527, 0.07424956,\n",
       "       0.03759978, 0.01133482, 0.04138724, 0.12624992, 0.02918389,\n",
       "       0.0921285 , 0.09201785, 0.08162197, 0.59724381, 0.38388745,\n",
       "       0.23169196, 0.37468722, 0.09072721, 0.15017889, 0.28000378,\n",
       "       0.06685818, 0.61508359, 0.20443337, 0.31810183, 0.11401757,\n",
       "       0.24569393, 0.15337762, 0.14369486, 0.02543012, 0.38922831,\n",
       "       0.19547068, 0.18098932, 0.0792928 , 0.25462509, 0.22437608,\n",
       "       0.02125878, 0.38567098, 0.35356953, 0.01001989, 0.20284972,\n",
       "       0.0354543 , 0.01088543, 0.02539035, 0.06353612, 0.25471227,\n",
       "       0.04861712, 0.15604861, 0.04243127, 0.24418889, 0.03658739,\n",
       "       0.02670544, 0.21945175, 0.12069539, 0.31883418, 0.1267886 ,\n",
       "       0.11664597, 0.17594775, 0.06020875, 0.1057228 , 0.20773433,\n",
       "       0.06778362, 0.04162321, 0.02750852, 0.20801876, 0.18722692,\n",
       "       0.0684802 , 0.57728728, 0.07158848, 0.14789172, 0.5107454 ,\n",
       "       0.02054199, 0.29984373, 0.21550728, 0.03008165, 0.02123562,\n",
       "       0.13149203, 0.40056466, 0.04191781, 0.26458643, 0.01882782,\n",
       "       0.08420998, 0.19233841, 0.02768842, 0.17293863, 0.24906036,\n",
       "       0.11323351, 0.19171692, 0.06698343, 0.5609193 , 0.36433605,\n",
       "       0.09107585, 0.05554985, 0.05613105, 0.32132393, 0.34747791,\n",
       "       0.16016278, 0.01581415, 0.18372182, 0.68259759, 0.25937297,\n",
       "       0.32268268, 0.10516456, 0.01909167, 0.10171099, 0.54779734,\n",
       "       0.16399385, 0.12685949, 0.23171438, 0.18588571, 0.08745098,\n",
       "       0.50681638, 0.34201937, 0.17647228, 0.0746433 , 0.01845639,\n",
       "       0.03824097, 0.24898369, 0.18480774, 0.13351778, 0.05812676,\n",
       "       0.15662714, 0.01314875, 0.39851511, 0.2990351 , 0.16690238,\n",
       "       0.29362434, 0.10983488, 0.3169955 , 0.15835263, 0.10228222,\n",
       "       0.05947739, 0.44372074, 0.04884728, 0.13540398, 0.17017918,\n",
       "       0.16984975, 0.01067311, 0.17049147, 0.0684927 , 0.15083831,\n",
       "       0.3545578 , 0.41088883, 0.01971368, 0.14055365, 0.12680858,\n",
       "       0.14057903, 0.06779431, 0.26586706, 0.3714167 , 0.06284799,\n",
       "       0.33395511, 0.06416296, 0.09416361, 0.71323681, 0.40305676,\n",
       "       0.41065594, 0.47376493, 0.0675008 , 0.08597985, 0.13961129,\n",
       "       0.14037172, 0.23726752, 0.23793916, 0.04434576, 0.10983484,\n",
       "       0.03326225, 0.24065819, 0.21770479, 0.01490815, 0.09968887,\n",
       "       0.01942179, 0.05074706, 0.09831254, 0.14315876, 0.0412378 ,\n",
       "       0.0521162 , 0.04722044, 0.23279195, 0.42981778, 0.0980508 ,\n",
       "       0.33486157, 0.03280534, 0.11084453, 0.30851313, 0.08275609,\n",
       "       0.15127483, 0.08863119, 0.02222416, 0.03251134, 0.06695838,\n",
       "       0.21631406, 0.04484387, 0.25858578, 0.19928029, 0.13595407,\n",
       "       0.04825324, 0.10801778, 0.10706301, 0.25866314, 0.42734276,\n",
       "       0.08472071, 0.18891125, 0.35400336, 0.13294299, 0.14236203,\n",
       "       0.12413593, 0.37983796, 0.07203719, 0.0266396 , 0.16046738,\n",
       "       0.18342169, 0.06756153, 0.03111613, 0.01257079, 0.40264512,\n",
       "       0.03350486, 0.01310506, 0.04293611, 0.12850742, 0.15396097,\n",
       "       0.11830977, 0.06591936, 0.12558099, 0.46039574, 0.13239539,\n",
       "       0.07081673, 0.0466821 , 0.01740352, 0.20402808, 0.05196559,\n",
       "       0.06074441, 0.25166873, 0.03904562, 0.53935914, 0.25450303,\n",
       "       0.2207252 , 0.12731853, 0.04522698, 0.05217128, 0.01315258,\n",
       "       0.03545733, 0.02923296, 0.47557098, 0.50701105, 0.09686214,\n",
       "       0.06518856, 0.25362738, 0.33711968, 0.15728914, 0.01974306,\n",
       "       0.01667195, 0.16783197, 0.09805733, 0.07360179, 0.16637648,\n",
       "       0.2633284 , 0.1828293 , 0.27270719, 0.08680149, 0.19712249,\n",
       "       0.24655903, 0.08105572, 0.56317824, 0.0625641 , 0.19850899,\n",
       "       0.05408069, 0.03352353, 0.16399345, 0.23476722, 0.03786612,\n",
       "       0.20177795, 0.13378719, 0.31961963, 0.02903666, 0.12080199,\n",
       "       0.30223062, 0.10538031, 0.32200029, 0.51043027, 0.0472499 ,\n",
       "       0.06803378, 0.07565472, 0.03063592, 0.04085912, 0.14750576]), count=array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.mode(lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00659721e-04, 0.00000000e+00, 6.71866779e-05, ...,\n",
       "        0.00000000e+00, 1.87893042e-03, 9.49965702e-03],\n",
       "       [1.35615162e-04, 9.00542717e-04, 2.41716938e-08, ...,\n",
       "        6.95212744e-08, 5.82136775e-03, 1.80706597e-03],\n",
       "       [2.95655303e-05, 3.24707332e-05, 7.62776683e-08, ...,\n",
       "        1.96422889e-07, 0.00000000e+00, 4.56455141e-03],\n",
       "       [5.32103402e-03, 7.99700914e-05, 3.41885343e-03, ...,\n",
       "        7.40578658e-04, 7.35425060e-03, 1.35452073e-03],\n",
       "       [7.43319979e-03, 3.58847573e-04, 0.00000000e+00, ...,\n",
       "        6.72027375e-04, 4.59674536e-03, 1.95999394e-04]])"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta, _, _ = sample_variational_params((lambd, gamma, phi))\n",
    "K, V = beta.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
