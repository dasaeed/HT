{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.special import gammaln, digamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_LDA(K, V, N, M, eta0=0.1, alpha0=0.5, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    beta = rs.dirichlet(np.full(V, eta0), size=K)\n",
    "    theta = rs.dirichlet(np.full(K, alpha0), size=N)\n",
    "    X = []\n",
    "    for i in range(N):\n",
    "        x_i = np.zeros(M[i], dtype=int)\n",
    "        for j in range(M[i]):\n",
    "            z_ij = rs.choice(K, p=theta[i]) + 1\n",
    "            x_ij = rs.choice(V, p=beta[z_ij-1]) + 1\n",
    "            x_i[j] = x_ij\n",
    "        X.append(x_i)\n",
    "    return X\n",
    "\n",
    "def get_unique_idxs(X):\n",
    "    N = len(X)\n",
    "    Ms = [len(x_i) for x_i in X]\n",
    "    unique_idxs = []\n",
    "\n",
    "    for i in range(N):\n",
    "        unique_idxs_i = np.zeros(Ms[i], dtype=int)\n",
    "        for j in range(Ms[i]):\n",
    "            unique_idxs_i[j] = X[i][j] - 1\n",
    "        unique_idxs_i = np.unique(np.sort(unique_idxs_i))\n",
    "        unique_idxs.append(unique_idxs_i)\n",
    "    return unique_idxs\n",
    "\n",
    "def get_idx_counts(X, unique_idxs):\n",
    "    N = len(X)\n",
    "    idx_counts = []\n",
    "\n",
    "    for i in range(N):\n",
    "        counts = np.zeros(len(unique_idxs[i]), dtype=int)\n",
    "        for j, val in enumerate(unique_idxs[i]):\n",
    "            counts[j] = np.sum(X[i].astype(float) == (val+1))\n",
    "        idx_counts.append(counts)\n",
    "    return idx_counts\n",
    "\n",
    "def init_variational_params(X, K, V, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    N = len(X)\n",
    "    Ms = np.array([len(x_i) for x_i in X])\n",
    "    lambd = rs.uniform(low=0.01, high=1.0, size=(K, V))\n",
    "    # lambd = np.full((K, V), 1.0)\n",
    "    gamma = np.ones((N, K))\n",
    "    phi = []\n",
    "    for M_i in Ms:\n",
    "        phi_i = np.ones((M_i, K))\n",
    "        phi_i = phi_i / K\n",
    "        phi.append(phi_i)\n",
    "    return lambd, gamma, phi\n",
    "\n",
    "def log_dir(x, alpha):\n",
    "    return gammaln(np.sum(alpha)) - np.sum(gammaln(alpha)) + np.sum((alpha-1) * np.log(x + 1e-10))\n",
    "\n",
    "def compute_ELBO(lambd, gamma, phi, unique_idxs, num_occs):\n",
    "    N = gamma.shape[0]\n",
    "\n",
    "    E_log_p_beta = np.sum((eta0-1) * (digamma(lambd) - digamma(np.sum(lambd, axis=1, keepdims=True))))\n",
    "    E_log_p_theta = np.sum((alpha0-1) * (digamma(gamma) - digamma(np.sum(gamma, axis=1, keepdims=True))))\n",
    "    E_log_q_beta = np.sum(-gammaln(np.sum(lambd, axis=1)) + np.sum(gammaln(lambd), axis=1) \\\n",
    "            - np.sum((lambd - 1) * (digamma(lambd) - digamma(np.sum(lambd, axis=1, keepdims=True))), axis=1))\n",
    "    E_log_q_theta = np.sum(-gammaln(np.sum(gamma, axis=1)) + np.sum(gammaln(gamma), axis=1) \\\n",
    "            - np.sum((gamma - 1) * (digamma(gamma) - digamma(np.sum(gamma, axis=1, keepdims=True))), axis=1))\n",
    "    \n",
    "    E_log_p_x_z = 0.0\n",
    "    for i in range(N):\n",
    "        unique_idx = unique_idxs[i]\n",
    "        counts = num_occs[i]\n",
    "        j = 0\n",
    "        for idx in unique_idx:\n",
    "            E_log_p_x_z += counts[j] * np.sum(phi[i][j] * (digamma(gamma[i])-digamma(np.sum(gamma[i])))) \\\n",
    "                + counts[j] * np.sum(phi[i][j] * (digamma(lambd[:, idx])-digamma(np.sum(lambd, axis=1))))\n",
    "            j += 1\n",
    "\n",
    "    E_log_q_z = 0.0\n",
    "    for i in range(N):\n",
    "        unique_idx = unique_idxs[i]\n",
    "        counts = num_occs[i]\n",
    "        j = 0\n",
    "        for idx in unique_idx:\n",
    "            E_log_q_z += -np.sum(phi[i][j] * np.log(phi[i][j]))\n",
    "            j += 1\n",
    "    return E_log_p_beta + E_log_p_theta + E_log_q_beta + E_log_q_theta + E_log_p_x_z + E_log_q_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_variational_params(var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    K, V = lambd.shape\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    \n",
    "    beta = np.zeros((K, V))\n",
    "    for k in range(K):\n",
    "        # beta[k] = npr.dirichlet(lambd[k])\n",
    "        beta[k] = npr.dirichlet(lambd[k]) + 1e-10\n",
    "        beta[k] /= beta[k].sum()\n",
    "    \n",
    "    theta = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        # theta[i] = npr.dirichlet(gamma[i])\n",
    "        theta[i] = npr.dirichlet(gamma[i]) + 1e-10\n",
    "        theta[i] /= theta[i].sum()\n",
    "\n",
    "    z = []\n",
    "    for i in range(N):\n",
    "        z_i = np.zeros(Ms[i], dtype=int)\n",
    "        for j in range(Ms[i]):\n",
    "            z_i[j] = npr.choice(K, p=phi[i][j]) + 1\n",
    "        z.append(z_i)\n",
    "    \n",
    "    return beta, theta, z\n",
    "\n",
    "def log_variational_dist(latent_params, var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    beta, theta, z = latent_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "\n",
    "    log_q = 0.0\n",
    "    for k in range(K):\n",
    "        log_q += log_dir(beta[k], lambd[k])\n",
    "\n",
    "    for i in range(N):\n",
    "        log_q += log_dir(theta[i], gamma[i])\n",
    "        for j in range(Ms[i]):\n",
    "            for k in range(K):\n",
    "                log_q += float(z[i][j]-1 == k) * np.log(phi[i][j, k] + eps)\n",
    "    return log_q\n",
    "\n",
    "def log_joint_prob(latent_params, X):\n",
    "    beta, theta, z = latent_params\n",
    "    K, V = beta.shape\n",
    "    N = theta.shape[0]\n",
    "    Ms = np.array([len(z[i]) for i in range(len(z))])\n",
    "\n",
    "    log_p = 0.0\n",
    "    for k in range(K):\n",
    "        log_p += log_dir(beta[k], np.full(V, eta0))\n",
    "\n",
    "    for i in range(N):\n",
    "        log_p += log_dir(theta[i], np.full(K, alpha0))\n",
    "        for j in range(Ms[i]):\n",
    "            z_ij, x_ij = z[i][j], X[i][j]\n",
    "            log_p += np.log(theta[i, z_ij-1])\n",
    "            log_p += np.log(beta[z_ij-1, x_ij-1])\n",
    "    return log_p\n",
    "\n",
    "def score_variational_dist(latent_params, var_params):\n",
    "    beta, theta, z = latent_params\n",
    "    lambd, gamma, phi = var_params\n",
    "    K, V = lambd.shape\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    grad_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "\n",
    "    for k in range(K):\n",
    "        grad_lambda_k = np.zeros(V)\n",
    "        for v in range(V):\n",
    "            grad_lambda_k[v] = digamma(np.sum(lambd[k])) - digamma(lambd[k, v]) + np.log(beta[k, v] + 1e-10)\n",
    "        grad_lambda[k] = grad_lambda_k\n",
    "    \n",
    "    for i in range(N):\n",
    "        grad_gamma_i = np.zeros(K)\n",
    "        for k in range(K):\n",
    "            grad_gamma_i[k] = digamma(np.sum(gamma[i])) - digamma(gamma[i, k]) + np.log(theta[i, k] + 1e-10)\n",
    "        grad_gamma[i] = grad_gamma_i\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(Ms[i]):\n",
    "            grad_phi_ij = np.zeros(K)\n",
    "            for k in range(K):\n",
    "                grad_phi_ij[k] = float(z[i][j]-1 == k) / phi[i][j, k]\n",
    "            grad_phi[i][j] = grad_phi_ij\n",
    "    return grad_lambda, grad_gamma, grad_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4983.819658127381\n",
      "-4983.905264196464\n",
      "-4983.966246182873\n",
      "-4984.014674972568\n",
      "-4984.057099537765\n",
      "-4984.095234404971\n",
      "-4984.1303220457\n",
      "-4984.162286111251\n",
      "-4984.192364114485\n",
      "-4984.220846626944\n",
      "-4984.247522591442\n",
      "-4984.272862917039\n",
      "-4984.297307809569\n",
      "-4984.320495357874\n",
      "-4984.343256898017\n",
      "-4984.364996246092\n",
      "-4984.386148615327\n",
      "-4984.406784340388\n",
      "-4984.426870423872\n",
      "-4984.446353703554\n",
      "-4984.465077389978\n",
      "-4984.483426421914\n",
      "-4984.501413378982\n",
      "-4984.5193670972885\n",
      "-4984.536480717368\n",
      "-4984.553444428044\n",
      "-4984.569771104143\n",
      "-4984.58586665467\n",
      "-4984.602068564449\n",
      "-4984.6178513271025\n",
      "-4984.633326861395\n",
      "-4984.648659238888\n",
      "-4984.663519965062\n",
      "-4984.678264753955\n",
      "-4984.692983680963\n",
      "-4984.7073993318545\n",
      "-4984.721552714937\n",
      "-4984.735491770767\n",
      "-4984.749233657117\n",
      "-4984.763031949853\n",
      "-4984.7761146502435\n",
      "-4984.78914840146\n",
      "-4984.8022983259925\n",
      "-4984.815128298545\n",
      "-4984.827903438429\n",
      "-4984.840589780726\n",
      "-4984.85304804686\n",
      "-4984.865530555126\n",
      "-4984.877682327683\n",
      "-4984.889785022901\n",
      "-4984.9018345623035\n",
      "-4984.913781412323\n",
      "-4984.925604192054\n",
      "-4984.937293332086\n",
      "-4984.948780526705\n",
      "-4984.960274566062\n",
      "-4984.971576221358\n",
      "-4984.982731334842\n",
      "-4984.993815197629\n",
      "-4985.004813771334\n",
      "-4985.01563692032\n",
      "-4985.026512400274\n",
      "-4985.03743441463\n",
      "-4985.048089291499\n",
      "-4985.058920672185\n",
      "-4985.0693002323205\n",
      "-4985.079592040437\n",
      "-4985.089914275986\n",
      "-4985.100330922035\n",
      "-4985.110568102701\n",
      "-4985.12048470653\n",
      "-4985.1304493235975\n",
      "-4985.14046934748\n",
      "-4985.150622925264\n",
      "-4985.160476982173\n",
      "-4985.17015324966\n",
      "-4985.179908119455\n",
      "-4985.1896151887295\n",
      "-4985.199185146328\n",
      "-4985.20890719306\n",
      "-4985.2184324475975\n",
      "-4985.227826407984\n",
      "-4985.237178276059\n",
      "-4985.246450117431\n",
      "-4985.2557875194625\n",
      "-4985.265078956099\n",
      "-4985.274240762314\n",
      "-4985.283141564695\n",
      "-4985.292141460862\n",
      "-4985.30095029908\n",
      "-4985.309885929588\n",
      "-4985.318725920959\n",
      "-4985.327462716339\n",
      "-4985.3363360685735\n",
      "-4985.345168787828\n",
      "-4985.353765182308\n",
      "-4985.362455391256\n",
      "-4985.370997053656\n",
      "-4985.3796051880745\n",
      "-4985.388110888355\n",
      "-4985.396555898885\n",
      "-4985.405153142436\n",
      "-4985.413455407283\n",
      "-4985.421856494089\n",
      "-4985.430182649427\n",
      "-4985.438662730808\n",
      "-4985.446890191526\n",
      "-4985.455150228859\n",
      "-4985.463360331314\n",
      "-4985.471401791355\n",
      "-4985.479446316981\n",
      "-4985.487387032404\n",
      "-4985.495329302784\n",
      "-4985.503390816746\n",
      "-4985.511317622824\n",
      "-4985.5191261851405\n",
      "-4985.526999957414\n",
      "-4985.5347279357875\n",
      "-4985.542565858912\n",
      "-4985.55036254828\n",
      "-4985.558170485904\n",
      "-4985.565998343811\n",
      "-4985.5736163314705\n",
      "-4985.581259912407\n",
      "-4985.58885623483\n",
      "-4985.596445732412\n",
      "-4985.60403780859\n",
      "-4985.611540252838\n",
      "-4985.618999261617\n",
      "-4985.626400697962\n",
      "-4985.63379283604\n",
      "-4985.641269028505\n",
      "-4985.648788123048\n",
      "-4985.656065305789\n",
      "-4985.663411118532\n",
      "-4985.670844572543\n",
      "-4985.6780341609865\n",
      "-4985.685312668946\n",
      "-4985.692495025524\n",
      "-4985.699733000976\n",
      "-4985.706972058821\n",
      "-4985.714104274521\n",
      "-4985.721281446986\n",
      "-4985.728454701835\n",
      "-4985.735533681352\n",
      "-4985.742512200733\n",
      "-4985.749499633264\n",
      "-4985.756444243732\n",
      "-4985.763379196561\n",
      "-4985.7703155861045\n",
      "-4985.777333400466\n",
      "-4985.784329824236\n",
      "-4985.79125738911\n",
      "-4985.798044486848\n",
      "-4985.804835462797\n",
      "-4985.8118011067345\n",
      "-4985.818505585838\n",
      "-4985.825269761335\n",
      "-4985.832076065309\n",
      "-4985.838863968898\n",
      "-4985.845641018401\n",
      "-4985.852498204627\n",
      "-4985.8592295139315\n",
      "-4985.865805069945\n",
      "-4985.872502823098\n",
      "-4985.879193478316\n",
      "-4985.885863121045\n",
      "-4985.89241783214\n",
      "-4985.8990148034645\n",
      "-4985.905525942311\n",
      "-4985.912122421678\n",
      "-4985.918557901285\n",
      "-4985.925113506412\n",
      "-4985.931542842585\n",
      "-4985.937933089753\n",
      "-4985.94436012681\n",
      "-4985.950753625065\n",
      "-4985.957221000443\n",
      "-4985.963654770158\n",
      "-4985.9700171784325\n",
      "-4985.97641736773\n",
      "-4985.982659047642\n",
      "-4985.989075878159\n",
      "-4985.995395683679\n",
      "-4986.001625642979\n",
      "-4986.00791499375\n",
      "-4986.014198144783\n",
      "-4986.020311320037\n",
      "-4986.026461605909\n",
      "-4986.032617067122\n",
      "-4986.038754773302\n",
      "-4986.044943729859\n",
      "-4986.051071201027\n",
      "-4986.057158216453\n",
      "-4986.063265325708\n",
      "-4986.069445859661\n",
      "-4986.0755307390455\n",
      "-4986.08158056741\n",
      "-4986.087537081057\n",
      "-4986.09362288442\n",
      "-4986.099783798044\n",
      "-4986.105843082428\n",
      "-4986.111840154867\n",
      "-4986.11778855274\n",
      "-4986.123761221051\n",
      "-4986.129716862976\n",
      "-4986.135620167336\n",
      "-4986.141535104207\n",
      "-4986.147471116113\n",
      "-4986.153369116701\n",
      "-4986.159291958416\n",
      "-4986.165165966919\n",
      "-4986.171019010221\n",
      "-4986.176831899727\n",
      "-4986.182595189222\n",
      "-4986.188410960653\n",
      "-4986.194114762029\n",
      "-4986.199922376464\n",
      "-4986.20562423743\n",
      "-4986.211474932552\n",
      "-4986.217209719425\n",
      "-4986.222950912348\n",
      "-4986.228638288901\n",
      "-4986.234393403368\n",
      "-4986.240079449569\n",
      "-4986.245800729873\n",
      "-4986.251513559937\n",
      "-4986.257094588181\n",
      "-4986.262666169968\n",
      "-4986.26822502702\n",
      "-4986.273808865471\n",
      "-4986.279394686857\n",
      "-4986.2850887253535\n",
      "-4986.290751472713\n",
      "-4986.296215324247\n",
      "-4986.301734109409\n",
      "-4986.307350540591\n",
      "-4986.312903862065\n",
      "-4986.318497797207\n",
      "-4986.323960644038\n",
      "-4986.329456532309\n",
      "-4986.334920818653\n",
      "-4986.340530880867\n",
      "-4986.345969150613\n",
      "-4986.3513870627785\n",
      "-4986.356838709785\n",
      "-4986.362335851619\n",
      "-4986.367714237996\n",
      "-4986.37310026749\n",
      "-4986.378467445829\n",
      "-4986.383849349052\n",
      "-4986.38936064689\n",
      "-4986.394730854046\n",
      "-4986.400117034064\n",
      "-4986.405480316199\n",
      "-4986.410699642142\n",
      "-4986.416063739551\n",
      "-4986.421416278202\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1283], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(S):\n\u001b[0;32m     27\u001b[0m     beta_s, theta_s, z_s \u001b[38;5;241m=\u001b[39m sample_variational_params((lambd, gamma, phi))\n\u001b[1;32m---> 28\u001b[0m     grad_lambda_s, grad_gamma_s, grad_phi_s \u001b[38;5;241m=\u001b[39m \u001b[43mscore_variational_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_s\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     log_p, log_q \u001b[38;5;241m=\u001b[39m log_joint_prob((beta_s, theta_s, z_s), X), log_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n\u001b[0;32m     30\u001b[0m     grad_lambda \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad_lambda_s \u001b[38;5;241m*\u001b[39m (log_p \u001b[38;5;241m-\u001b[39m log_q)\n",
      "Cell \u001b[1;32mIn[1250], line 90\u001b[0m, in \u001b[0;36mscore_variational_dist\u001b[1;34m(latent_params, var_params)\u001b[0m\n\u001b[0;32m     88\u001b[0m         grad_phi_ij \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(K)\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[1;32m---> 90\u001b[0m             grad_phi_ij[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m phi[i][j, k]\n\u001b[0;32m     91\u001b[0m         grad_phi[i][j] \u001b[38;5;241m=\u001b[39m grad_phi_ij\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_lambda, grad_gamma, grad_phi\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rs = npr.RandomState(0)\n",
    "eta0 = 0.3\n",
    "alpha0 = 0.5\n",
    "K = 5\n",
    "V = 100\n",
    "N = 10\n",
    "M = npr.poisson(50, size=N)\n",
    "X = simulate_LDA(K, V, N, M, eta0, alpha0)\n",
    "unique_idxs = get_unique_idxs(X)\n",
    "num_occs = get_idx_counts(X, unique_idxs)\n",
    "\n",
    "S = 20\n",
    "rho = 1e-6\n",
    "eps = 1e-6\n",
    "lambd, gamma, phi = init_variational_params(X, K, V)\n",
    "G_lambda = np.zeros_like(lambd)\n",
    "G_gamma = np.zeros_like(gamma)\n",
    "G_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "\n",
    "print(compute_ELBO(lambd, gamma, phi, unique_idxs, num_occs))\n",
    "\n",
    "for t in range(1000):\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    grad_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "    for s in range(S):\n",
    "        beta_s, theta_s, z_s = sample_variational_params((lambd, gamma, phi))\n",
    "        grad_lambda_s, grad_gamma_s, grad_phi_s = score_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        log_p, log_q = log_joint_prob((beta_s, theta_s, z_s), X), log_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        grad_lambda += grad_lambda_s * (log_p - log_q)\n",
    "        grad_gamma += grad_gamma_s * (log_p - log_q)\n",
    "        for i in range(len(grad_phi)):\n",
    "            grad_phi[i] += grad_phi_s[i] * (log_p - log_q)\n",
    "    grad_lambda /= S\n",
    "    grad_gamma /= S\n",
    "    grad_phi = [g_phi / S for g_phi in grad_phi]\n",
    "\n",
    "    G_lambda += np.square(grad_lambda)\n",
    "    G_gamma += np.square(grad_gamma)\n",
    "    G_phi = [G_p + np.square(g_p) for G_p, g_p in zip(G_phi, grad_phi)]\n",
    "\n",
    "    rho_lambda = rho / (np.sqrt(G_lambda) + eps)\n",
    "    rho_gamma = rho / (np.sqrt(G_gamma) + eps)\n",
    "    rho_phi = [rho / (np.sqrt(G_p) + eps) for G_p in G_phi]\n",
    "\n",
    "    lambd += rho_lambda * grad_lambda\n",
    "    lambd = np.maximum(lambd, 1e-3)\n",
    "    gamma += rho_gamma * grad_gamma\n",
    "    gamma = np.maximum(gamma, 1e-3)\n",
    "    for i in range(len(phi)):\n",
    "        phi[i] += rho_phi[i] * grad_phi[i]\n",
    "        phi[i] = np.maximum(phi[i], 1e-10)\n",
    "        phi[i] /= phi[i].sum(axis=1, keepdims=True)\n",
    "            \n",
    "        # if t % 100 == 0:\n",
    "        #     print(t)\n",
    "    print(compute_ELBO(lambd, gamma, phi, unique_idxs, num_occs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = npr.dirichlet(npr.random(10))\n",
    "np.sum(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72772895, 0.68986909, 0.5139746 , 0.81693573, 0.67666415,\n",
       "       0.72916291, 0.52684395, 0.71954486, 0.78033844, 0.74273193,\n",
       "       0.5948293 , 0.67831366, 0.60617041, 0.37333081, 0.9905991 ,\n",
       "       0.34404053, 0.54714105, 0.87253999, 0.3270894 , 0.84705663,\n",
       "       0.80041732, 0.4112345 , 0.47779821, 0.76437366, 0.98003957,\n",
       "       0.59814953, 0.66800309, 0.65138105, 0.84521121, 0.69373105,\n",
       "       0.55705901, 0.56451172, 0.40557593, 0.69829906, 0.64126996,\n",
       "       0.78974439, 0.42131593, 0.71449213, 0.85733011, 0.71171898,\n",
       "       0.59919093, 0.70407542, 0.66668948, 0.56677303, 0.52834288,\n",
       "       0.998471  , 0.87207133, 0.90712203, 0.71797699, 0.37034996,\n",
       "       0.6840777 , 0.84403024, 0.65780185, 0.93805543, 0.78395794,\n",
       "       0.61876346, 1.02362356, 0.92187373, 0.95010749, 0.67143199,\n",
       "       0.92023049, 0.68014147, 0.68260278, 0.96160331, 0.61899003,\n",
       "       0.62203863, 0.84426588, 0.84446863, 0.75051007, 0.84629898,\n",
       "       0.63250784, 0.77954966, 0.75507628, 0.71519343, 0.5847906 ,\n",
       "       0.74794242, 0.64556063, 0.5406613 , 0.37227337, 0.31101483,\n",
       "       0.90366619, 0.6904615 , 0.76596365, 0.71273474, 0.88767109,\n",
       "       0.63523562, 0.6411594 , 0.57761737, 0.72279556, 0.83528621,\n",
       "       0.50525405, 0.94916917, 0.94062822, 0.66223325, 0.82746224,\n",
       "       0.75078566, 0.96478768, 0.69170986, 0.60962017, 0.59946932])"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.mode(lambd)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
