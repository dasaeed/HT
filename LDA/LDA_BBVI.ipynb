{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.special import gammaln, digamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_LDA(K, V, N, M, eta0=0.1, alpha0=0.5, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    beta = rs.dirichlet(np.full(V, eta0), size=K)\n",
    "    theta = rs.dirichlet(np.full(K, alpha0), size=N)\n",
    "    X = []\n",
    "    for i in range(N):\n",
    "        x_i = np.zeros(M[i], dtype=int)\n",
    "        for j in range(M[i]):\n",
    "            z_ij = rs.choice(K, p=theta[i]) + 1\n",
    "            x_ij = rs.choice(V, p=beta[z_ij-1]) + 1\n",
    "            x_i[j] = x_ij\n",
    "        X.append(x_i)\n",
    "    return X\n",
    "\n",
    "def get_unique_idxs(X):\n",
    "    N = len(X)\n",
    "    Ms = [len(x_i) for x_i in X]\n",
    "    unique_idxs = []\n",
    "\n",
    "    for i in range(N):\n",
    "        unique_idxs_i = np.zeros(Ms[i], dtype=int)\n",
    "        for j in range(Ms[i]):\n",
    "            unique_idxs_i[j] = X[i][j] - 1\n",
    "        unique_idxs_i = np.unique(np.sort(unique_idxs_i))\n",
    "        unique_idxs.append(unique_idxs_i)\n",
    "    return unique_idxs\n",
    "\n",
    "def get_idx_counts(X, unique_idxs):\n",
    "    N = len(X)\n",
    "    idx_counts = []\n",
    "\n",
    "    for i in range(N):\n",
    "        counts = np.zeros(len(unique_idxs[i]), dtype=int)\n",
    "        for j, val in enumerate(unique_idxs[i]):\n",
    "            counts[j] = np.sum(X[i].astype(float) == (val+1))\n",
    "        idx_counts.append(counts)\n",
    "    return idx_counts\n",
    "\n",
    "def init_variational_params(X, K, V, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    N = len(X)\n",
    "    Ms = np.array([len(x_i) for x_i in X])\n",
    "    lambd = rs.uniform(low=0.01, high=1.0, size=(K, V))\n",
    "    # lambd = np.full((K, V), 1.0)\n",
    "    gamma = np.ones((N, K))\n",
    "    phi = []\n",
    "    for M_i in Ms:\n",
    "        phi_i = np.ones((M_i, K))\n",
    "        phi_i = phi_i / K\n",
    "        phi.append(phi_i)\n",
    "    return lambd, gamma, phi\n",
    "\n",
    "def log_dir(x, alpha):\n",
    "    return gammaln(np.sum(alpha)) - np.sum(gammaln(alpha)) + np.sum((alpha-1) * np.log(x + 1e-10))\n",
    "\n",
    "def compute_ELBO(lambd, gamma, phi, unique_idxs, num_occs):\n",
    "    N = gamma.shape[0]\n",
    "\n",
    "    E_log_p_beta = np.sum((eta0-1) * (digamma(lambd) - digamma(np.sum(lambd, axis=1, keepdims=True))))\n",
    "    E_log_p_theta = np.sum((alpha0-1) * (digamma(gamma) - digamma(np.sum(gamma, axis=1, keepdims=True))))\n",
    "    E_log_q_beta = np.sum(-gammaln(np.sum(lambd, axis=1)) + np.sum(gammaln(lambd), axis=1) \\\n",
    "            - np.sum((lambd - 1) * (digamma(lambd) - digamma(np.sum(lambd, axis=1, keepdims=True))), axis=1))\n",
    "    E_log_q_theta = np.sum(-gammaln(np.sum(gamma, axis=1)) + np.sum(gammaln(gamma), axis=1) \\\n",
    "            - np.sum((gamma - 1) * (digamma(gamma) - digamma(np.sum(gamma, axis=1, keepdims=True))), axis=1))\n",
    "    \n",
    "    E_log_p_x_z = 0.0\n",
    "    for i in range(N):\n",
    "        unique_idx = unique_idxs[i]\n",
    "        counts = num_occs[i]\n",
    "        j = 0\n",
    "        for idx in unique_idx:\n",
    "            E_log_p_x_z += counts[j] * np.sum(phi[i][j] * (digamma(gamma[i])-digamma(np.sum(gamma[i])))) \\\n",
    "                + counts[j] * np.sum(phi[i][j] * (digamma(lambd[:, idx])-digamma(np.sum(lambd, axis=1))))\n",
    "            j += 1\n",
    "\n",
    "    E_log_q_z = 0.0\n",
    "    for i in range(N):\n",
    "        unique_idx = unique_idxs[i]\n",
    "        counts = num_occs[i]\n",
    "        j = 0\n",
    "        for idx in unique_idx:\n",
    "            E_log_q_z += -np.sum(phi[i][j] * np.log(phi[i][j]))\n",
    "            j += 1\n",
    "    return E_log_p_beta + E_log_p_theta + E_log_q_beta + E_log_q_theta + E_log_p_x_z + E_log_q_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_variational_params(var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    K, V = lambd.shape\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    \n",
    "    beta = np.zeros((K, V))\n",
    "    for k in range(K):\n",
    "        # beta[k] = npr.dirichlet(lambd[k])\n",
    "        beta[k] = npr.dirichlet(lambd[k]) + 1e-10\n",
    "        beta[k] /= beta[k].sum()\n",
    "    \n",
    "    theta = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        # theta[i] = npr.dirichlet(gamma[i])\n",
    "        theta[i] = npr.dirichlet(gamma[i]) + 1e-10\n",
    "        theta[i] /= theta[i].sum()\n",
    "\n",
    "    z = []\n",
    "    for i in range(N):\n",
    "        z_i = np.zeros(Ms[i], dtype=int)\n",
    "        for j in range(Ms[i]):\n",
    "            z_i[j] = npr.choice(K, p=phi[i][j]) + 1\n",
    "        z.append(z_i)\n",
    "    \n",
    "    return beta, theta, z\n",
    "\n",
    "def log_variational_dist(latent_params, var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    beta, theta, z = latent_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "\n",
    "    log_q = 0.0\n",
    "    for k in range(K):\n",
    "        log_q += log_dir(beta[k], lambd[k])\n",
    "\n",
    "    for i in range(N):\n",
    "        log_q += log_dir(theta[i], gamma[i])\n",
    "        for j in range(Ms[i]):\n",
    "            for k in range(K):\n",
    "                log_q += float(z[i][j]-1 == k) * np.log(phi[i][j, k] + eps)\n",
    "    return log_q\n",
    "\n",
    "def log_joint_prob(latent_params, X):\n",
    "    beta, theta, z = latent_params\n",
    "    K, V = beta.shape\n",
    "    N = theta.shape[0]\n",
    "    Ms = np.array([len(z[i]) for i in range(len(z))])\n",
    "\n",
    "    log_p = 0.0\n",
    "    for k in range(K):\n",
    "        log_p += log_dir(beta[k], np.full(V, eta0))\n",
    "\n",
    "    for i in range(N):\n",
    "        log_p += log_dir(theta[i], np.full(K, alpha0))\n",
    "        for j in range(Ms[i]):\n",
    "            z_ij, x_ij = z[i][j], X[i][j]\n",
    "            log_p += np.log(theta[i, z_ij-1])\n",
    "            log_p += np.log(beta[z_ij-1, x_ij-1])\n",
    "    return log_p\n",
    "\n",
    "def score_variational_dist(latent_params, var_params):\n",
    "    beta, theta, z = latent_params\n",
    "    lambd, gamma, phi = var_params\n",
    "    K, V = lambd.shape\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    grad_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "\n",
    "    for k in range(K):\n",
    "        grad_lambda_k = np.zeros(V)\n",
    "        for v in range(V):\n",
    "            grad_lambda_k[v] = digamma(np.sum(lambd[k])) - digamma(lambd[k, v]) + np.log(beta[k, v] + 1e-10)\n",
    "        grad_lambda[k] = grad_lambda_k\n",
    "    \n",
    "    for i in range(N):\n",
    "        grad_gamma_i = np.zeros(K)\n",
    "        for k in range(K):\n",
    "            grad_gamma_i[k] = digamma(np.sum(gamma[i])) - digamma(gamma[i, k]) + np.log(theta[i, k] + 1e-10)\n",
    "        grad_gamma[i] = grad_gamma_i\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(Ms[i]):\n",
    "            grad_phi_ij = np.zeros(K)\n",
    "            for k in range(K):\n",
    "                grad_phi_ij[k] = float(z[i][j]-1 == k) / phi[i][j, k]\n",
    "            grad_phi[i][j] = grad_phi_ij\n",
    "    return grad_lambda, grad_gamma, grad_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4983.819658127381\n",
      "-4983.905264196464\n",
      "-4983.966246182873\n",
      "-4984.014674972568\n",
      "-4984.057099537765\n",
      "-4984.095234404971\n",
      "-4984.1303220457\n",
      "-4984.162286111251\n",
      "-4984.192364114485\n",
      "-4984.220846626944\n",
      "-4984.247522591442\n",
      "-4984.272862917039\n",
      "-4984.297307809569\n",
      "-4984.320495357874\n",
      "-4984.343256898017\n",
      "-4984.364996246092\n",
      "-4984.386148615327\n",
      "-4984.406784340388\n",
      "-4984.426870423872\n",
      "-4984.446353703554\n",
      "-4984.465077389978\n",
      "-4984.483426421914\n",
      "-4984.501413378982\n",
      "-4984.5193670972885\n",
      "-4984.536480717368\n",
      "-4984.553444428044\n",
      "-4984.569771104143\n",
      "-4984.58586665467\n",
      "-4984.602068564449\n",
      "-4984.6178513271025\n",
      "-4984.633326861395\n",
      "-4984.648659238888\n",
      "-4984.663519965062\n",
      "-4984.678264753955\n",
      "-4984.692983680963\n",
      "-4984.7073993318545\n",
      "-4984.721552714937\n",
      "-4984.735491770767\n",
      "-4984.749233657117\n",
      "-4984.763031949853\n",
      "-4984.7761146502435\n",
      "-4984.78914840146\n",
      "-4984.8022983259925\n",
      "-4984.815128298545\n",
      "-4984.827903438429\n",
      "-4984.840589780726\n",
      "-4984.85304804686\n",
      "-4984.865530555126\n",
      "-4984.877682327683\n",
      "-4984.889785022901\n",
      "-4984.9018345623035\n",
      "-4984.913781412323\n",
      "-4984.925604192054\n",
      "-4984.937293332086\n",
      "-4984.948780526705\n",
      "-4984.960274566062\n",
      "-4984.971576221358\n",
      "-4984.982731334842\n",
      "-4984.993815197629\n",
      "-4985.004813771334\n",
      "-4985.01563692032\n",
      "-4985.026512400274\n",
      "-4985.03743441463\n",
      "-4985.048089291499\n",
      "-4985.058920672185\n",
      "-4985.0693002323205\n",
      "-4985.079592040437\n",
      "-4985.089914275986\n",
      "-4985.100330922035\n",
      "-4985.110568102701\n",
      "-4985.12048470653\n",
      "-4985.1304493235975\n",
      "-4985.14046934748\n",
      "-4985.150622925264\n",
      "-4985.160476982173\n",
      "-4985.17015324966\n",
      "-4985.179908119455\n",
      "-4985.1896151887295\n",
      "-4985.199185146328\n",
      "-4985.20890719306\n",
      "-4985.2184324475975\n",
      "-4985.227826407984\n",
      "-4985.237178276059\n",
      "-4985.246450117431\n",
      "-4985.2557875194625\n",
      "-4985.265078956099\n",
      "-4985.274240762314\n",
      "-4985.283141564695\n",
      "-4985.292141460862\n",
      "-4985.30095029908\n",
      "-4985.309885929588\n",
      "-4985.318725920959\n",
      "-4985.327462716339\n",
      "-4985.3363360685735\n",
      "-4985.345168787828\n",
      "-4985.353765182308\n",
      "-4985.362455391256\n",
      "-4985.370997053656\n",
      "-4985.3796051880745\n",
      "-4985.388110888355\n",
      "-4985.396555898885\n",
      "-4985.405153142436\n",
      "-4985.413455407283\n",
      "-4985.421856494089\n",
      "-4985.430182649427\n",
      "-4985.438662730808\n",
      "-4985.446890191526\n",
      "-4985.455150228859\n",
      "-4985.463360331314\n",
      "-4985.471401791355\n",
      "-4985.479446316981\n",
      "-4985.487387032404\n",
      "-4985.495329302784\n",
      "-4985.503390816746\n",
      "-4985.511317622824\n",
      "-4985.5191261851405\n",
      "-4985.526999957414\n",
      "-4985.5347279357875\n",
      "-4985.542565858912\n",
      "-4985.55036254828\n",
      "-4985.558170485904\n",
      "-4985.565998343811\n",
      "-4985.5736163314705\n",
      "-4985.581259912407\n",
      "-4985.58885623483\n",
      "-4985.596445732412\n",
      "-4985.60403780859\n",
      "-4985.611540252838\n",
      "-4985.618999261617\n",
      "-4985.626400697962\n",
      "-4985.63379283604\n",
      "-4985.641269028505\n",
      "-4985.648788123048\n",
      "-4985.656065305789\n",
      "-4985.663411118532\n",
      "-4985.670844572543\n",
      "-4985.6780341609865\n",
      "-4985.685312668946\n",
      "-4985.692495025524\n",
      "-4985.699733000976\n",
      "-4985.706972058821\n",
      "-4985.714104274521\n",
      "-4985.721281446986\n",
      "-4985.728454701835\n",
      "-4985.735533681352\n",
      "-4985.742512200733\n",
      "-4985.749499633264\n",
      "-4985.756444243732\n",
      "-4985.763379196561\n",
      "-4985.7703155861045\n",
      "-4985.777333400466\n",
      "-4985.784329824236\n",
      "-4985.79125738911\n",
      "-4985.798044486848\n",
      "-4985.804835462797\n",
      "-4985.8118011067345\n",
      "-4985.818505585838\n",
      "-4985.825269761335\n",
      "-4985.832076065309\n",
      "-4985.838863968898\n",
      "-4985.845641018401\n",
      "-4985.852498204627\n",
      "-4985.8592295139315\n",
      "-4985.865805069945\n",
      "-4985.872502823098\n",
      "-4985.879193478316\n",
      "-4985.885863121045\n",
      "-4985.89241783214\n",
      "-4985.8990148034645\n",
      "-4985.905525942311\n",
      "-4985.912122421678\n",
      "-4985.918557901285\n",
      "-4985.925113506412\n",
      "-4985.931542842585\n",
      "-4985.937933089753\n",
      "-4985.94436012681\n",
      "-4985.950753625065\n",
      "-4985.957221000443\n",
      "-4985.963654770158\n",
      "-4985.9700171784325\n",
      "-4985.97641736773\n",
      "-4985.982659047642\n",
      "-4985.989075878159\n",
      "-4985.995395683679\n",
      "-4986.001625642979\n",
      "-4986.00791499375\n",
      "-4986.014198144783\n",
      "-4986.020311320037\n",
      "-4986.026461605909\n",
      "-4986.032617067122\n",
      "-4986.038754773302\n",
      "-4986.044943729859\n",
      "-4986.051071201027\n",
      "-4986.057158216453\n",
      "-4986.063265325708\n",
      "-4986.069445859661\n",
      "-4986.0755307390455\n",
      "-4986.08158056741\n",
      "-4986.087537081057\n",
      "-4986.09362288442\n",
      "-4986.099783798044\n",
      "-4986.105843082428\n",
      "-4986.111840154867\n",
      "-4986.11778855274\n",
      "-4986.123761221051\n",
      "-4986.129716862976\n",
      "-4986.135620167336\n",
      "-4986.141535104207\n",
      "-4986.147471116113\n",
      "-4986.153369116701\n",
      "-4986.159291958416\n",
      "-4986.165165966919\n",
      "-4986.171019010221\n",
      "-4986.176831899727\n",
      "-4986.182595189222\n",
      "-4986.188410960653\n",
      "-4986.194114762029\n",
      "-4986.199922376464\n",
      "-4986.20562423743\n",
      "-4986.211474932552\n",
      "-4986.217209719425\n",
      "-4986.222950912348\n",
      "-4986.228638288901\n",
      "-4986.234393403368\n",
      "-4986.240079449569\n",
      "-4986.245800729873\n",
      "-4986.251513559937\n",
      "-4986.257094588181\n",
      "-4986.262666169968\n",
      "-4986.26822502702\n",
      "-4986.273808865471\n",
      "-4986.279394686857\n",
      "-4986.2850887253535\n",
      "-4986.290751472713\n",
      "-4986.296215324247\n",
      "-4986.301734109409\n",
      "-4986.307350540591\n",
      "-4986.312903862065\n",
      "-4986.318497797207\n",
      "-4986.323960644038\n",
      "-4986.329456532309\n",
      "-4986.334920818653\n",
      "-4986.340530880867\n",
      "-4986.345969150613\n",
      "-4986.3513870627785\n",
      "-4986.356838709785\n",
      "-4986.362335851619\n",
      "-4986.367714237996\n",
      "-4986.37310026749\n",
      "-4986.378467445829\n",
      "-4986.383849349052\n",
      "-4986.38936064689\n",
      "-4986.394730854046\n",
      "-4986.400117034064\n",
      "-4986.405480316199\n",
      "-4986.410699642142\n",
      "-4986.416063739551\n",
      "-4986.421416278202\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1283], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(S):\n\u001b[0;32m     27\u001b[0m     beta_s, theta_s, z_s \u001b[38;5;241m=\u001b[39m sample_variational_params((lambd, gamma, phi))\n\u001b[1;32m---> 28\u001b[0m     grad_lambda_s, grad_gamma_s, grad_phi_s \u001b[38;5;241m=\u001b[39m \u001b[43mscore_variational_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_s\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     log_p, log_q \u001b[38;5;241m=\u001b[39m log_joint_prob((beta_s, theta_s, z_s), X), log_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n\u001b[0;32m     30\u001b[0m     grad_lambda \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad_lambda_s \u001b[38;5;241m*\u001b[39m (log_p \u001b[38;5;241m-\u001b[39m log_q)\n",
      "Cell \u001b[1;32mIn[1250], line 90\u001b[0m, in \u001b[0;36mscore_variational_dist\u001b[1;34m(latent_params, var_params)\u001b[0m\n\u001b[0;32m     88\u001b[0m         grad_phi_ij \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(K)\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K):\n\u001b[1;32m---> 90\u001b[0m             grad_phi_ij[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m phi[i][j, k]\n\u001b[0;32m     91\u001b[0m         grad_phi[i][j] \u001b[38;5;241m=\u001b[39m grad_phi_ij\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_lambda, grad_gamma, grad_phi\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rs = npr.RandomState(0)\n",
    "eta0 = 0.3\n",
    "alpha0 = 0.5\n",
    "K = 5\n",
    "V = 100\n",
    "N = 10\n",
    "M = npr.poisson(50, size=N)\n",
    "X = simulate_LDA(K, V, N, M, eta0, alpha0)\n",
    "unique_idxs = get_unique_idxs(X)\n",
    "num_occs = get_idx_counts(X, unique_idxs)\n",
    "\n",
    "S = 20\n",
    "rho = 1e-6\n",
    "eps = 1e-6\n",
    "lambd, gamma, phi = init_variational_params(X, K, V)\n",
    "G_lambda = np.zeros_like(lambd)\n",
    "G_gamma = np.zeros_like(gamma)\n",
    "G_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "\n",
    "print(compute_ELBO(lambd, gamma, phi, unique_idxs, num_occs))\n",
    "\n",
    "for t in range(1000):\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    grad_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "    for s in range(S):\n",
    "        beta_s, theta_s, z_s = sample_variational_params((lambd, gamma, phi))\n",
    "        grad_lambda_s, grad_gamma_s, grad_phi_s = score_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        log_p, log_q = log_joint_prob((beta_s, theta_s, z_s), X), log_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        grad_lambda += grad_lambda_s * (log_p - log_q)\n",
    "        grad_gamma += grad_gamma_s * (log_p - log_q)\n",
    "        for i in range(len(grad_phi)):\n",
    "            grad_phi[i] += grad_phi_s[i] * (log_p - log_q)\n",
    "    grad_lambda /= S\n",
    "    grad_gamma /= S\n",
    "    grad_phi = [g_phi / S for g_phi in grad_phi]\n",
    "\n",
    "    G_lambda += np.square(grad_lambda)\n",
    "    G_gamma += np.square(grad_gamma)\n",
    "    G_phi = [G_p + np.square(g_p) for G_p, g_p in zip(G_phi, grad_phi)]\n",
    "\n",
    "    rho_lambda = rho / (np.sqrt(G_lambda) + eps)\n",
    "    rho_gamma = rho / (np.sqrt(G_gamma) + eps)\n",
    "    rho_phi = [rho / (np.sqrt(G_p) + eps) for G_p in G_phi]\n",
    "\n",
    "    lambd += rho_lambda * grad_lambda\n",
    "    lambd = np.maximum(lambd, 1e-3)\n",
    "    gamma += rho_gamma * grad_gamma\n",
    "    gamma = np.maximum(gamma, 1e-3)\n",
    "    for i in range(len(phi)):\n",
    "        phi[i] += rho_phi[i] * grad_phi[i]\n",
    "        phi[i] = np.maximum(phi[i], 1e-10)\n",
    "        phi[i] /= phi[i].sum(axis=1, keepdims=True)\n",
    "            \n",
    "        # if t % 100 == 0:\n",
    "        #     print(t)\n",
    "    print(compute_ELBO(lambd, gamma, phi, unique_idxs, num_occs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.00346299, 1.00336161, 1.00031725, 1.00413804,\n",
       "        1.00568828, 1.        , 1.        , 1.00005877, 1.0002066 ,\n",
       "        1.        , 1.0085892 , 1.00428117, 1.01208755, 1.00050942,\n",
       "        1.01014529, 1.        , 1.00292325, 1.01744589, 1.        ,\n",
       "        1.0018596 , 1.00618972, 1.00173486, 1.00002366, 1.00044266,\n",
       "        1.        , 1.00771825, 1.01150733, 1.00256214, 1.00117589,\n",
       "        1.00008221, 1.        , 1.00875977, 1.        , 1.        ,\n",
       "        1.01172746, 1.00043438, 1.00234683, 1.        , 1.        ,\n",
       "        1.0020654 , 1.00128344, 1.00616477, 1.00279991, 1.00153313,\n",
       "        1.        , 1.        , 1.00179698, 1.00007665, 1.01499926,\n",
       "        1.        , 1.        , 1.00005689, 1.        , 1.        ,\n",
       "        1.00139097, 1.0062881 , 1.        , 1.        , 1.        ,\n",
       "        1.00887612, 1.        , 1.        , 1.00634993, 1.01246871,\n",
       "        1.        , 1.01116507, 1.01497582, 1.00831365, 1.00022908,\n",
       "        1.00128752, 1.00428388, 1.        , 1.00001423, 1.00260789,\n",
       "        1.        , 1.01151511, 1.        , 1.00786415, 1.        ,\n",
       "        1.00383395, 1.        , 1.        , 1.00393493, 1.00502084,\n",
       "        1.        , 1.00256956, 1.        , 1.        , 1.00730372,\n",
       "        1.00288704, 1.        , 1.00386572, 1.00009053, 1.        ,\n",
       "        1.        , 1.00025714, 1.        , 1.00514676, 1.        ],\n",
       "       [1.00229478, 1.00425768, 1.01060565, 1.00478268, 1.        ,\n",
       "        1.00562796, 1.        , 1.        , 1.00312697, 1.01002547,\n",
       "        1.00099647, 1.        , 1.        , 1.01533473, 1.        ,\n",
       "        1.        , 1.00286305, 1.        , 1.        , 1.00194943,\n",
       "        1.00875389, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.0041829 , 1.        , 1.        , 1.01668662,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.00784713,\n",
       "        1.        , 1.        , 1.00168475, 1.        , 1.        ,\n",
       "        1.00448977, 1.00749659, 1.        , 1.00652786, 1.00217663,\n",
       "        1.0004707 , 1.01858779, 1.        , 1.        , 1.        ,\n",
       "        1.0011219 , 1.00343793, 1.00058177, 1.00663961, 1.00248557,\n",
       "        1.00942901, 1.00598803, 1.00389012, 1.        , 1.        ,\n",
       "        1.        , 1.00940237, 1.        , 1.        , 1.00213916,\n",
       "        1.        , 1.00031254, 1.0053659 , 1.00753973, 1.        ,\n",
       "        1.00812914, 1.        , 1.00188891, 1.        , 1.00353626,\n",
       "        1.        , 1.00005656, 1.0091222 , 1.00322556, 1.00549016,\n",
       "        1.00705626, 1.00007414, 1.        , 1.        , 1.        ,\n",
       "        1.00298552, 1.01064352, 1.00627713, 1.00399597, 1.        ,\n",
       "        1.00694429, 1.00203749, 1.        , 1.00588997, 1.00605177,\n",
       "        1.        , 1.00143023, 1.        , 1.00089447, 1.00074836],\n",
       "       [1.        , 1.00631536, 1.00625401, 1.        , 1.00551669,\n",
       "        1.        , 1.00151938, 1.00483084, 1.        , 1.        ,\n",
       "        1.00606978, 1.00048486, 1.00286399, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.00314722, 1.        , 1.00796588,\n",
       "        1.        , 1.        , 1.        , 1.00750389, 1.00524007,\n",
       "        1.0161349 , 1.01044406, 1.00330642, 1.00028   , 1.01530236,\n",
       "        1.00061828, 1.00981634, 1.00193772, 1.00495631, 1.        ,\n",
       "        1.        , 1.        , 1.01537594, 1.00727913, 1.00093523,\n",
       "        1.        , 1.00491576, 1.        , 1.00342801, 1.00175233,\n",
       "        1.        , 1.009185  , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.01299971, 1.00710853, 1.00186269, 1.        ,\n",
       "        1.00974711, 1.0119332 , 1.0055201 , 1.        , 1.00508419,\n",
       "        1.0004387 , 1.00613836, 1.00035466, 1.00007436, 1.00179671,\n",
       "        1.        , 1.00502576, 1.00927336, 1.        , 1.00478847,\n",
       "        1.        , 1.        , 1.01109175, 1.        , 1.        ,\n",
       "        1.00163734, 1.0016722 , 1.00824727, 1.00898118, 1.00510556,\n",
       "        1.0059586 , 1.00339875, 1.        , 1.        , 1.00388506,\n",
       "        1.00059489, 1.00396722, 1.0007154 , 1.        , 1.00062568,\n",
       "        1.        , 1.00018162, 1.        , 1.        , 1.00010678,\n",
       "        1.00188957, 1.        , 1.00843645, 1.        , 1.00273061],\n",
       "       [1.        , 1.        , 1.00837316, 1.01245242, 1.00807758,\n",
       "        1.00013779, 1.        , 1.0001519 , 1.00165288, 1.0023137 ,\n",
       "        1.        , 1.        , 1.        , 1.00101411, 1.00290463,\n",
       "        1.00990857, 1.00005435, 1.000101  , 1.00758914, 1.        ,\n",
       "        1.00477023, 1.00143186, 1.00678855, 1.        , 1.00330227,\n",
       "        1.00002994, 1.00097887, 1.        , 1.00169602, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.00154173, 1.00058518,\n",
       "        1.00893737, 1.0000598 , 1.        , 1.        , 1.00033156,\n",
       "        1.00370573, 1.00311887, 1.00289498, 1.        , 1.01140045,\n",
       "        1.0005401 , 1.00056844, 1.        , 1.00446364, 1.        ,\n",
       "        1.0044493 , 1.01317343, 1.00155567, 1.00104554, 1.        ,\n",
       "        1.00425219, 1.00050109, 1.00099684, 1.        , 1.00188746,\n",
       "        1.00674534, 1.        , 1.00011689, 1.00288432, 1.        ,\n",
       "        1.0183987 , 1.00001646, 1.00310022, 1.01843972, 1.00658847,\n",
       "        1.00630545, 1.        , 1.00258443, 1.        , 1.00899566,\n",
       "        1.00039455, 1.00634909, 1.0040022 , 1.00312917, 1.00172444,\n",
       "        1.01789801, 1.00656897, 1.        , 1.        , 1.        ,\n",
       "        1.00635271, 1.00011025, 1.00962181, 1.00132211, 1.00002568,\n",
       "        1.00192237, 1.        , 1.00144401, 1.00736601, 1.01590107,\n",
       "        1.        , 1.00246674, 1.00703289, 1.        , 1.01374146],\n",
       "       [1.00238014, 1.        , 1.00613302, 1.00694647, 1.        ,\n",
       "        1.        , 1.        , 1.00531952, 1.00571233, 1.00030932,\n",
       "        1.        , 1.        , 1.00405617, 1.        , 1.00303692,\n",
       "        1.        , 1.00402868, 1.00705458, 1.00407862, 1.00321597,\n",
       "        1.00094593, 1.00147202, 1.00193063, 1.00886479, 1.01362272,\n",
       "        1.00488159, 1.00006066, 1.        , 1.00031297, 1.00022098,\n",
       "        1.00282497, 1.00085902, 1.        , 1.0069141 , 1.        ,\n",
       "        1.        , 1.00102144, 1.        , 1.01722725, 1.        ,\n",
       "        1.00332962, 1.00306318, 1.00510018, 1.00474251, 1.00451353,\n",
       "        1.00384403, 1.        , 1.00036923, 1.        , 1.00556392,\n",
       "        1.        , 1.        , 1.01269909, 1.        , 1.        ,\n",
       "        1.        , 1.00032727, 1.00474464, 1.00956806, 1.00795618,\n",
       "        1.        , 1.00133829, 1.00424362, 1.00193279, 1.00575333,\n",
       "        1.00131262, 1.0002819 , 1.00520269, 1.        , 1.0082237 ,\n",
       "        1.00697338, 1.00092507, 1.00042811, 1.00706234, 1.00171488,\n",
       "        1.        , 1.00576307, 1.00062104, 1.        , 1.        ,\n",
       "        1.00187698, 1.00777385, 1.01428507, 1.00940884, 1.        ,\n",
       "        1.01611892, 1.        , 1.0101285 , 1.        , 1.00535187,\n",
       "        1.        , 1.0003441 , 1.01003997, 1.00769618, 1.        ,\n",
       "        1.00051233, 1.00612468, 1.00176672, 1.00613141, 1.00005492]])"
      ]
     },
     "execution_count": 1281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72772895, 0.68986909, 0.5139746 , 0.81693573, 0.67666415,\n",
       "       0.72916291, 0.52684395, 0.71954486, 0.78033844, 0.74273193,\n",
       "       0.5948293 , 0.67831366, 0.60617041, 0.37333081, 0.9905991 ,\n",
       "       0.34404053, 0.54714105, 0.87253999, 0.3270894 , 0.84705663,\n",
       "       0.80041732, 0.4112345 , 0.47779821, 0.76437366, 0.98003957,\n",
       "       0.59814953, 0.66800309, 0.65138105, 0.84521121, 0.69373105,\n",
       "       0.55705901, 0.56451172, 0.40557593, 0.69829906, 0.64126996,\n",
       "       0.78974439, 0.42131593, 0.71449213, 0.85733011, 0.71171898,\n",
       "       0.59919093, 0.70407542, 0.66668948, 0.56677303, 0.52834288,\n",
       "       0.998471  , 0.87207133, 0.90712203, 0.71797699, 0.37034996,\n",
       "       0.6840777 , 0.84403024, 0.65780185, 0.93805543, 0.78395794,\n",
       "       0.61876346, 1.02362356, 0.92187373, 0.95010749, 0.67143199,\n",
       "       0.92023049, 0.68014147, 0.68260278, 0.96160331, 0.61899003,\n",
       "       0.62203863, 0.84426588, 0.84446863, 0.75051007, 0.84629898,\n",
       "       0.63250784, 0.77954966, 0.75507628, 0.71519343, 0.5847906 ,\n",
       "       0.74794242, 0.64556063, 0.5406613 , 0.37227337, 0.31101483,\n",
       "       0.90366619, 0.6904615 , 0.76596365, 0.71273474, 0.88767109,\n",
       "       0.63523562, 0.6411594 , 0.57761737, 0.72279556, 0.83528621,\n",
       "       0.50525405, 0.94916917, 0.94062822, 0.66223325, 0.82746224,\n",
       "       0.75078566, 0.96478768, 0.69170986, 0.60962017, 0.59946932])"
      ]
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.mode(lambd)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
