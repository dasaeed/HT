{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.special import gammaln, digamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_LDA(K, V, N, M, eta=0.1, alpha=0.5, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    beta = rs.dirichlet(np.full(V, eta), size=K)\n",
    "    theta = rs.dirichlet(np.full(K, alpha), size=N)\n",
    "    X = []\n",
    "    for i in range(N):\n",
    "        x_i = np.zeros(M[i], dtype=int)\n",
    "        for j in range(M[i]):\n",
    "            z_ij = rs.choice(K, p=theta[i])\n",
    "            x_ij = rs.choice(V, p=beta[z_ij])\n",
    "            x_i[j] = x_ij\n",
    "        X.append(x_i)\n",
    "    return X\n",
    "\n",
    "def init_variational_params(X, K, V):\n",
    "    N = len(X)\n",
    "    Ms = np.array([len(x_i) for x_i in X])\n",
    "    lambd = npr.uniform(low=0.01, high=1.0, size=(K, V))\n",
    "    gamma = np.ones((N, K))\n",
    "    phi = []\n",
    "    for M_i in Ms:\n",
    "        phi_i = np.ones((M_i, K))\n",
    "        phi_i = phi_i / K\n",
    "        phi.append(phi_i)\n",
    "    return lambd, gamma, phi\n",
    "\n",
    "B = 100\n",
    "rs = npr.RandomState(0)\n",
    "eta = 0.1\n",
    "alpha = 0.5\n",
    "K = 10\n",
    "V = 500\n",
    "N = 50\n",
    "M = npr.poisson(100, size=N)\n",
    "X = simulate_LDA(K, V, N, M, eta, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dir(x, alpha):\n",
    "    return digamma(np.sum(alpha)) - digamma(alpha)\n",
    "\n",
    "def score_cat(z, phi):\n",
    "    return z / phi\n",
    "\n",
    "def sample_variational_params(params, num_samples):\n",
    "    lambd_params, gamma_params, phi_params = params\n",
    "    K, V = lambd.shape\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    betas = []\n",
    "    thetas = []\n",
    "    zs = []\n",
    "    for _ in range(num_samples):\n",
    "        beta = np.zeros((K, V))\n",
    "        for k in range(K):\n",
    "            beta[k] = npr.dirichlet(lambd_params[k])\n",
    "        \n",
    "        theta = np.zeros((N, K))\n",
    "        for i in range(N):\n",
    "            theta[i] = npr.dirichlet(gamma_params[i])\n",
    "\n",
    "        z = []\n",
    "        for i in range(N):\n",
    "            z_i = np.zeros(Ms[i], dtype=int)\n",
    "            for j in range(Ms[i]):\n",
    "                z_i[j] = npr.choice(K, p=phi_params[i][j])\n",
    "            z.append(z_i)\n",
    "        betas.append(beta)\n",
    "        thetas.append(theta)\n",
    "        zs.append(z)\n",
    "    if num_samples == 1:\n",
    "        return betas[0], thetas[0], zs[0]\n",
    "    else:\n",
    "        return betas, thetas, zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dir(x, alpha):\n",
    "    return gammaln(np.sum(alpha)) - np.sum(gammaln(alpha)) + np.sum((alpha-1) * np.log(x))\n",
    "\n",
    "def log_variational_dist(latent_params, var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    beta, theta, z = latent_params\n",
    "\n",
    "    log_q_beta = 0.0\n",
    "    for k in range(K):\n",
    "        log_q_beta += log_dir(beta[k], lambd[k])\n",
    "    \n",
    "    log_q_theta = 0.0\n",
    "    for i in range(N):\n",
    "        log_q_theta += log_dir(theta[i], gamma[i])\n",
    "\n",
    "    log_q_z = 0.0\n",
    "    for i in range(N):\n",
    "        for j in range(Ms[i]):\n",
    "            for k in range(K):\n",
    "                log_q_z += float(z[i][j] == k) * np.log(phi[i][j, k])\n",
    "    return log_q_beta + log_q_theta + log_q_z\n",
    "\n",
    "def log_joint_prob(latent_params, X):\n",
    "    beta, theta, z = latent_params\n",
    "    K, V = beta.shape\n",
    "    N = theta.shape[0]\n",
    "    Ms = np.array([len(z[i]) for i in range(len(z))])\n",
    "\n",
    "    log_p_beta = 0.0\n",
    "    for k in range(K):\n",
    "        log_p_beta += log_dir(beta[k], np.full(V, eta))\n",
    "\n",
    "    log_p_theta = 0.0\n",
    "    log_p_z = 0.0\n",
    "    log_p_x = 0.0\n",
    "    for i in range(N):\n",
    "        log_p_theta += log_dir(theta[i], np.full(K, alpha))\n",
    "        for j in range(Ms[i]):\n",
    "            log_p_z += np.log(theta[i, z[i][j]])\n",
    "            log_p_x += np.log(beta[z[i][j], X[i][j]])\n",
    "    return log_p_beta + log_p_theta + log_p_z + log_p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_variational_dist(latent_params, var_params):\n",
    "    beta, theta, z = latent_params\n",
    "    lambd, gamma, phi = var_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    grad_phi = [np.zeros_like(phi[i]) for i in range(N)]\n",
    "\n",
    "    for k in range(K):\n",
    "        grad_lambda[k] = score_dir(beta[k], lambd[k])\n",
    "    \n",
    "    for i in range(N):\n",
    "        grad_gamma[i] = score_dir(theta[k], gamma[k])\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(Ms[i]):\n",
    "            for k in range(K):\n",
    "                grad_phi[i][j, k] = float(z[i][j] == k) / phi[i][j, k]\n",
    "    return grad_lambda, grad_gamma, grad_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        ...,\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001],\n",
       "        [0.001, 0.001, 0.001, ..., 0.001, 0.001, 0.001]]),\n",
       " 0.001)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 10e-4\n",
    "eps = 10e-6\n",
    "S = 10\n",
    "lambd, gamma, phi = init_variational_params(X, K, V)\n",
    "beta_samp, theta_samp, z_samp = sample_variational_params((lambd, gamma, phi), S)\n",
    "accum_grad_lambda, accum_grad_gamma, accum_grad_phi = 0, 0, None\n",
    "\n",
    "for s in range(S):\n",
    "    grad_lambda, grad_gamma, grad_phi = score_variational_dist((beta_samp[s], theta_samp[s], z_samp[s]), (lambd, gamma, phi))\n",
    "    accum_grad_lambda += grad_lambda\n",
    "    accum_grad_gamma += grad_gamma\n",
    "    # accum_grad_phi += grad_phi\n",
    "\n",
    "# lambd + (accum_grad_lambda / S)\n",
    "(lr / np.sqrt((np.square(accum_grad_lambda) + eps))) * accum_grad_lambda, 10e-4\n",
    "# grad_lambda * (log_joint_prob((beta, theta, z), X) - log_variational_dist((beta, theta, z), (lambd, gamma, phi)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
