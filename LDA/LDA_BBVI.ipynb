{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.special import gammaln, digamma\n",
    "eps = 1e-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_LDA(K, V, N, M, eta0=0.1, alpha0=0.5, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    beta = rs.dirichlet(np.full(V, eta0), size=K)\n",
    "    theta = rs.dirichlet(np.full(K, alpha0), size=N)\n",
    "    X = []\n",
    "    for i in range(N):\n",
    "        x_i = np.zeros(M[i], dtype=int)\n",
    "        for j in range(M[i]):\n",
    "            z_ij = rs.choice(K, p=theta[i]) + 1\n",
    "            x_ij = rs.choice(V, p=beta[z_ij-1]) + 1\n",
    "            x_i[j] = x_ij\n",
    "        X.append(x_i)\n",
    "    return X\n",
    "\n",
    "def init_variational_params(X, K, V):\n",
    "    N = len(X)\n",
    "    Ms = np.array([len(x_i) for x_i in X])\n",
    "    lambd = npr.uniform(low=0.01, high=1.0, size=(K, V))\n",
    "    # lambd = np.full((K, V), 1.0)\n",
    "    gamma = np.ones((N, K))\n",
    "    phi = []\n",
    "    for M_i in Ms:\n",
    "        phi_i = np.ones((M_i, K))\n",
    "        phi_i = phi_i / K\n",
    "        phi.append(phi_i)\n",
    "    return lambd, gamma, phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_variational_params(var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    K, V = lambd.shape\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    \n",
    "    beta = np.zeros((K, V))\n",
    "    for k in range(K):\n",
    "        beta[k] = npr.dirichlet(lambd[k]) + 1e-10\n",
    "        beta[k] /= beta[k].sum()\n",
    "    \n",
    "    theta = np.zeros((N, K))\n",
    "    for i in range(N):\n",
    "        theta[i] = npr.dirichlet(gamma[i]) + 1e-10\n",
    "        theta[i] /= theta[i].sum()\n",
    "\n",
    "    z = []\n",
    "    for i in range(N):\n",
    "        z_i = np.zeros(Ms[i], dtype=int)\n",
    "        for j in range(Ms[i]):\n",
    "            z_i[j] = npr.choice(K, p=phi[i][j]) + 1\n",
    "        z.append(z_i)\n",
    "    \n",
    "    return beta, theta, z\n",
    "\n",
    "def log_dir(x, alpha):\n",
    "    return gammaln(np.sum(alpha)) - np.sum(gammaln(alpha)) + np.sum((alpha-1) * np.log(x + 1e-10))\n",
    "\n",
    "def log_variational_dist(latent_params, var_params):\n",
    "    lambd, gamma, phi = var_params\n",
    "    beta, theta, z = latent_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "\n",
    "    log_q = 0.0\n",
    "    for k in range(K):\n",
    "        log_q += log_dir(beta[k], lambd[k])\n",
    "\n",
    "    for i in range(N):\n",
    "        log_q += log_dir(theta[i], gamma[i])\n",
    "        for j in range(Ms[i]):\n",
    "            for k in range(K):\n",
    "                log_q += float(z[i][j]-1 == k) * np.log(phi[i][j, k] + eps)\n",
    "    return log_q\n",
    "\n",
    "def log_joint_prob(latent_params, X):\n",
    "    beta, theta, z = latent_params\n",
    "    K, V = beta.shape\n",
    "    N = theta.shape[0]\n",
    "    Ms = np.array([len(z[i]) for i in range(len(z))])\n",
    "\n",
    "    log_p = 0.0\n",
    "    for k in range(K):\n",
    "        log_p += log_dir(beta[k], np.full(V, eta0))\n",
    "\n",
    "    for i in range(N):\n",
    "        log_p += log_dir(theta[i], np.full(K, alpha0))\n",
    "        for j in range(Ms[i]):\n",
    "            z_ij, x_ij = z[i][j], X[i][j]\n",
    "            log_p += np.log(theta[i, z_ij-1])\n",
    "            log_p += np.log(beta[z_ij-1, x_ij-1])\n",
    "    return log_p\n",
    "\n",
    "def score_variational_dist(latent_params, var_params):\n",
    "    beta, theta, z = latent_params\n",
    "    lambd, gamma, phi = var_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    Ms = np.array([len(phi[i]) for i in range(len(phi))])\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    grad_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "\n",
    "    for k in range(K):\n",
    "        grad_lambda_k = np.zeros(V)\n",
    "        for v in range(V):\n",
    "            grad_lambda_k[v] = digamma(np.sum(lambd[k])) - digamma(lambd[k, v]) + np.log(beta[k, v] + 1e-10)\n",
    "        grad_lambda[k] = grad_lambda_k\n",
    "    \n",
    "    for i in range(N):\n",
    "        grad_gamma_i = np.zeros(K)\n",
    "        for k in range(K):\n",
    "            grad_gamma_i[k] = digamma(np.sum(gamma[i])) - digamma(gamma[i, k]) + np.log(theta[i, k] + 1e-10)\n",
    "        grad_gamma[i] = grad_gamma_i\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(Ms[i]):\n",
    "            grad_phi_ij = np.zeros(K)\n",
    "            for k in range(K):\n",
    "                grad_phi_ij[k] = float(z[i][j]-1 == k) / phi[i][j, k]\n",
    "            grad_phi[i][j] = grad_phi_ij\n",
    "    return grad_lambda, grad_gamma, grad_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "rs = npr.RandomState(0)\n",
    "eta0 = 0.3\n",
    "alpha0 = 0.5\n",
    "K = 5\n",
    "V = 100\n",
    "N = 10\n",
    "M = npr.poisson(50, size=N)\n",
    "X = simulate_LDA(K, V, N, M, eta0, alpha0)\n",
    "\n",
    "S = 20\n",
    "eta = 0.04\n",
    "eps = 1e-6\n",
    "lambd, gamma, phi = init_variational_params(X, K, V)\n",
    "G_lambda = np.zeros_like(lambd)\n",
    "G_gamma = np.zeros_like(gamma)\n",
    "G_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "\n",
    "for t in range(300):\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    grad_phi = [np.zeros_like(phi_i) for phi_i in phi]\n",
    "    for s in range(S):\n",
    "        beta_s, theta_s, z_s = sample_variational_params((lambd, gamma, phi))\n",
    "        grad_lambda_s, grad_gamma_s, grad_phi_s = score_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        log_p, log_q = log_joint_prob((beta_s, theta_s, z_s), X), log_variational_dist((beta_s, theta_s, z_s), (lambd, gamma, phi))\n",
    "        grad_lambda += grad_lambda_s * (log_p - log_q)\n",
    "        grad_gamma += grad_gamma_s * (log_p - log_q)\n",
    "        for i in range(len(grad_phi)):\n",
    "            grad_phi[i] += grad_phi_s[i] * (log_p - log_q)\n",
    "    grad_lambda /= S\n",
    "    grad_gamma /= S\n",
    "    grad_phi = [g_phi / S for g_phi in grad_phi]\n",
    "\n",
    "    G_lambda += np.square(grad_lambda)\n",
    "    G_gamma += np.square(grad_gamma)\n",
    "    G_phi = [G_p + np.square(g_p) for G_p, g_p in zip(G_phi, grad_phi)]\n",
    "\n",
    "    rho_lambda = eta / np.sqrt(G_lambda + eps)\n",
    "    rho_gamma = eta / np.sqrt(G_gamma + eps)\n",
    "    rho_phi = [eta / np.sqrt(G_p + eps) for G_p in G_phi]\n",
    "\n",
    "    lambd += rho_lambda * grad_lambda\n",
    "    lambd = np.maximum(lambd, 1e-3)\n",
    "    gamma += rho_gamma * grad_gamma\n",
    "    gamma = np.maximum(gamma, 1e-3)\n",
    "    for i in range(len(phi)):\n",
    "        phi[i] += rho_phi[i] * grad_phi[i]\n",
    "        phi[i] = np.maximum(phi[i], 1e-10)\n",
    "        phi[i] /= phi[i].sum(axis=1, keepdims=True)\n",
    "        \n",
    "    if t % 100 == 0:\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.31964538, 0.33947036, 0.26728506, 0.32274846, 0.4740857 ,\n",
       "        0.41559834, 0.30780697, 0.5641044 , 0.27805669, 0.4614689 ,\n",
       "        0.26140196, 0.26279354, 0.28955787, 0.33479368, 0.35474976,\n",
       "        0.42149211, 0.42233743]),\n",
       " array([0.87462824, 0.88907063, 0.85539712, 0.76451928, 0.76181388]))"
      ]
     },
     "execution_count": 1141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.stats.mode(lambd)[0][scipy.stats.mode(lambd)[0] > 1e-3], scipy.stats.mode(gamma)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
