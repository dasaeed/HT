{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "from scipy.stats import mode\n",
    "from scipy.special import gammaln, digamma, logsumexp\n",
    "from scipy.stats import dirichlet as dir\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clean_text(text):\n",
    "    with open(\"vocab.txt\", \"r\") as file:\n",
    "        vocab = [line.strip() for line in file.readlines()]\n",
    "    vocab_set = set(vocab)\n",
    "    contractions = {\n",
    "        r\"n\\'t\": 'nt',\n",
    "        r\"\\'s\": 's',     \n",
    "        r\"\\'ve\": 've',   \n",
    "        r\"\\'re\": 're',   \n",
    "        r\"\\'m\": 'm',     \n",
    "        r\"\\'ll\": 'll',   \n",
    "        r\"\\'d\": 'd'      \n",
    "    }\n",
    "\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[.,!?;:\"``]', \" \", text)\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if \"'\" in word:\n",
    "            word_added = False\n",
    "            for pattern, replacement in contractions.items():\n",
    "                if word.endswith(pattern):\n",
    "                    contracted = word.replace(pattern, replacement)\n",
    "                    if contracted in vocab_set:\n",
    "                        words.append(contracted)\n",
    "                        word_added = True\n",
    "                        break\n",
    "            if not word_added:\n",
    "                combined = word.replace(\"'\", \"\")\n",
    "                if combined in vocab_set:\n",
    "                    words.append(combined)\n",
    "        if \"-\" in word:\n",
    "            combined = word.replace(\"-\", \"\")\n",
    "            if combined in vocab_set:\n",
    "                words.append(combined)\n",
    "                continue \n",
    "            parts = [p for p in word.split(\"-\") if p in vocab_set]\n",
    "            words.extend(parts)\n",
    "        else:\n",
    "            if word in vocab_set:\n",
    "                words.append(word)\n",
    "    return words\n",
    "\n",
    "rs = npr.RandomState(0)\n",
    "K, V, N = 10, 300, 30\n",
    "eta0, alpha0 = 0.8, 1 / K\n",
    "Ms = rs.poisson(60, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lda(K, V, N, Ms, eta0=(100 / V), alpha0=(1 / K), rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    beta = rs.dirichlet(np.full(V, eta0), size=K)\n",
    "    theta = rs.dirichlet(np.full(K, alpha0), size=N)\n",
    "    X = []\n",
    "    for i in range(N):\n",
    "        x_i = np.zeros(Ms[i], dtype=int)\n",
    "        for j in range(Ms[i]):\n",
    "            z_ij = rs.choice(K, p=theta[i])\n",
    "            x_ij = rs.choice(V, p=beta[z_ij])\n",
    "            x_i[j] = x_ij\n",
    "        X.append(x_i)\n",
    "    return X\n",
    "\n",
    "def init_var_params(X, K, V, rs_int=npr.randint(low=0, high=100)):\n",
    "    rs = npr.RandomState(rs_int)\n",
    "    N = len(X)\n",
    "    lambd = rs.uniform(low=0.5, high=1.0, size=(K, V))\n",
    "    gamma = rs.uniform(low=0.1, high=1.0, size=(N, K))\n",
    "    return np.log(lambd), np.log(gamma)\n",
    "\n",
    "def sample_params(var_params):\n",
    "    lambd, gamma = var_params\n",
    "    log_gamm_beta = np.log(npr.gamma(np.exp(lambd), 1))\n",
    "    log_probs_beta = log_gamm_beta - logsumexp(log_gamm_beta, axis=1)[:, None]\n",
    "    beta = np.exp(log_probs_beta)\n",
    "\n",
    "    log_gamm_gamma = np.log(npr.gamma(np.exp(gamma), 1))\n",
    "    log_probs_gamma = log_gamm_gamma - logsumexp(log_gamm_gamma, axis=1)[:, None]\n",
    "    theta = np.exp(log_probs_gamma)\n",
    "    return beta, theta\n",
    "\n",
    "def log_var_approx(var_params, latent_params):\n",
    "    lambd, gamma = var_params\n",
    "    beta, theta = latent_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "\n",
    "    log_q_beta = sum(dir.logpdf(beta[k], np.exp(lambd[k])) for k in range(K))\n",
    "    log_q_theta = sum(dir.logpdf(theta[i], np.exp(gamma[i])) for i in range(N))\n",
    "    return log_q_beta + log_q_theta\n",
    "\n",
    "def log_joint_prob(latent_params, X):\n",
    "    beta, theta = latent_params\n",
    "    K = beta.shape[0]\n",
    "    N = theta.shape[0]\n",
    "\n",
    "    log_p_beta = sum(dir.logpdf(beta[k], np.full(beta[k].shape, eta0)) for k in range(K))\n",
    "    log_p_theta = sum(dir.logpdf(theta[i], np.full(theta[i].shape, alpha0)) for i in range(N))\n",
    "    # log_p_x = 0.0\n",
    "    # for _, (theta_i, x_i) in enumerate(zip(theta, X)):\n",
    "    #     beta_xi = beta[:, x_i]\n",
    "    #     sum_word_probs = np.sum(np.log(theta_i[:, None] * beta_xi), axis=0)\n",
    "    #     log_p_x += np.sum(sum_word_probs)\n",
    "    log_p_x = 0.0\n",
    "    for _, (theta_i, x_i) in enumerate(zip(theta, X)):\n",
    "        beta_xi = beta[:, x_i]\n",
    "        sum_word_probs = np.log(np.sum(theta_i[:, None] * beta_xi, axis=0))\n",
    "        log_p_x += np.sum(sum_word_probs)\n",
    "    return log_p_beta + log_p_theta + log_p_x\n",
    "\n",
    "def score_dir(x, alpha):\n",
    "    return digamma(np.sum(alpha)) - digamma(alpha) + np.log(x)\n",
    "\n",
    "def score_var_dist(var_params, latent_params):\n",
    "    lambd, gamma = var_params\n",
    "    K = lambd.shape[0]\n",
    "    N = gamma.shape[0]\n",
    "    beta, theta = latent_params\n",
    "    grad_lambd, grad_gamma = np.zeros_like(lambd), np.zeros_like(gamma)\n",
    "    for k in range(K):\n",
    "        grad_lambd[k] = score_dir(beta[k], np.exp(lambd[k]))\n",
    "    for i in range(N):\n",
    "        grad_gamma[i] = score_dir(theta[i], np.exp(gamma[i]))\n",
    "\n",
    "    return grad_lambd, grad_gamma\n",
    "\n",
    "def estimate_ELBO(var_params, S):\n",
    "    lambd, gamma = var_params\n",
    "    ELBO = 0.0\n",
    "    for _ in range(S):\n",
    "        beta_s, theta_s = sample_params((lambd, gamma))\n",
    "        log_p = log_joint_prob((beta_s, theta_s), X)\n",
    "        log_q = log_var_approx((lambd, gamma), (beta_s, theta_s))\n",
    "        ELBO += (log_p - log_q)\n",
    "    return ELBO / S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, ELBO: -13371.746023153708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, ELBO: -13370.931252622811\n",
      "Iteration 200, ELBO: -13397.352084853559\n",
      "Iteration 300, ELBO: -13392.726513972657\n",
      "Iteration 400, ELBO: -13406.78992410707\n",
      "Iteration 500, ELBO: -13367.911623432581\n",
      "Iteration 600, ELBO: -13372.19465107983\n",
      "Iteration 700, ELBO: -13371.494888839943\n",
      "Iteration 800, ELBO: -13385.09060241537\n",
      "Iteration 900, ELBO: -13398.092660074675\n",
      "Iteration 1000, ELBO: -13349.880687024473\n",
      "Iteration 1100, ELBO: -13382.313483717255\n",
      "Iteration 1200, ELBO: -13385.789913591929\n",
      "Iteration 1300, ELBO: -13391.745463063568\n",
      "Iteration 1400, ELBO: -13393.486469392365\n",
      "Iteration 1500, ELBO: -13383.2251638499\n",
      "Iteration 1600, ELBO: -13413.518340372397\n",
      "Iteration 1700, ELBO: -13381.45179990262\n",
      "Iteration 1800, ELBO: -13385.477069685145\n",
      "Iteration 1900, ELBO: -13387.109518098547\n",
      "Iteration 2000, ELBO: -13360.521540952317\n",
      "Iteration 2100, ELBO: -13406.335815308174\n",
      "Iteration 2200, ELBO: -13356.32047709513\n",
      "Iteration 2300, ELBO: -13376.231041313053\n",
      "Iteration 2400, ELBO: -13368.501737154313\n",
      "Iteration 2500, ELBO: -13387.719363878068\n",
      "Iteration 2600, ELBO: -13369.499656290438\n",
      "Iteration 2700, ELBO: -13388.342080084552\n",
      "Iteration 2800, ELBO: -13399.309701311804\n",
      "Iteration 2900, ELBO: -13398.824216192636\n",
      "Iteration 3000, ELBO: -13380.915974577249\n",
      "Iteration 3100, ELBO: -13365.723913189862\n",
      "Iteration 3200, ELBO: -13378.253890593998\n",
      "Iteration 3300, ELBO: -13384.626202394484\n",
      "Iteration 3400, ELBO: -13383.102017922225\n",
      "Iteration 3500, ELBO: -13378.869731193063\n",
      "Iteration 3600, ELBO: -13392.797691248701\n",
      "Iteration 3700, ELBO: -13382.32646324131\n",
      "Iteration 3800, ELBO: -13369.574889256963\n",
      "Iteration 3900, ELBO: -13410.008932227569\n",
      "Iteration 4000, ELBO: -13373.555109069948\n",
      "Iteration 4100, ELBO: -13395.085639484987\n",
      "Iteration 4200, ELBO: -13371.805728468322\n",
      "Iteration 4300, ELBO: -13375.482947978806\n",
      "Iteration 4400, ELBO: -13360.928649875696\n",
      "Iteration 4500, ELBO: -13384.575527643154\n",
      "Iteration 4600, ELBO: -13378.908676597803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[632], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(S):\n\u001b[0;32m     26\u001b[0m     score_lambd, score_gamma \u001b[38;5;241m=\u001b[39m score_var_dist((lambd, gamma), (betas[s], thetas[s]))\n\u001b[1;32m---> 27\u001b[0m     log_p \u001b[38;5;241m=\u001b[39m \u001b[43mlog_joint_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     log_q \u001b[38;5;241m=\u001b[39m log_var_approx((lambd, gamma), (betas[s], thetas[s]))\n\u001b[0;32m     29\u001b[0m     stoch_score_grad_lambd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m score_lambd \u001b[38;5;241m*\u001b[39m (log_p \u001b[38;5;241m-\u001b[39m log_q)\n",
      "Cell \u001b[1;32mIn[628], line 58\u001b[0m, in \u001b[0;36mlog_joint_prob\u001b[1;34m(latent_params, X)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (theta_i, x_i) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(theta, X)):\n\u001b[0;32m     57\u001b[0m     beta_xi \u001b[38;5;241m=\u001b[39m beta[:, x_i]\n\u001b[1;32m---> 58\u001b[0m     sum_word_probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_i\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta_xi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     59\u001b[0m     log_p_x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(sum_word_probs)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_p_beta \u001b[38;5;241m+\u001b[39m log_p_theta \u001b[38;5;241m+\u001b[39m log_p_x\n",
      "File \u001b[1;32mc:\\Users\\daany\\anaconda3\\envs\\ht\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2344\u001b[0m, in \u001b[0;36m_sum_dispatcher\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2338\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `min` or `max` keyword argument when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2339\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m'\u001b[39m, a_min, a_max, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum_dispatcher\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2345\u001b[0m                     initial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, out)\n\u001b[0;32m   2349\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_sum_dispatcher)\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue,\n\u001b[0;32m   2351\u001b[0m         initial\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39m_NoValue):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rs = npr.RandomState(0)\n",
    "K, V, N = 10, 300, 30\n",
    "eta0, alpha0 = 0.1, 5 / K\n",
    "Ms = rs.poisson(60, size=N)\n",
    "S = 20\n",
    "eta = 1e-5\n",
    "eps = 1e-8\n",
    "\n",
    "X = generate_lda(K, V, N, Ms, eta0=eta0, alpha0=alpha0, rs_int=0)\n",
    "lambd, gamma = init_var_params(X, K, V, 0)\n",
    "G_lambd, G_gamma = np.zeros((V, V)), np.zeros((K, K))\n",
    "max_iters = 10001\n",
    "ELBOs = []\n",
    "\n",
    "for t in range(max_iters):\n",
    "    betas = []\n",
    "    thetas = []\n",
    "    for _ in range(S):\n",
    "        beta_s, theta_s = sample_params((lambd, gamma))\n",
    "        betas.append(beta_s)\n",
    "        thetas.append(theta_s)\n",
    "\n",
    "    stoch_score_grad_lambd = np.zeros_like(lambd)\n",
    "    stoch_score_grad_gamma = np.zeros_like(gamma)\n",
    "    for s in range(S):\n",
    "        score_lambd, score_gamma = score_var_dist((lambd, gamma), (betas[s], thetas[s]))\n",
    "        log_p = log_joint_prob((betas[s], thetas[s]), X)\n",
    "        log_q = log_var_approx((lambd, gamma), (betas[s], thetas[s]))\n",
    "        stoch_score_grad_lambd += score_lambd * (log_p - log_q)\n",
    "        stoch_score_grad_gamma += score_gamma * (log_p - log_q)\n",
    "    stoch_score_grad_lambd /= S\n",
    "    stoch_score_grad_gamma /= S\n",
    "\n",
    "    for k in range(K):\n",
    "        G_lambd += np.outer(stoch_score_grad_lambd[k], stoch_score_grad_lambd[k])\n",
    "    rho_lambd = eta * (G_lambd.diagonal() + eps)**(-0.5)\n",
    "\n",
    "    for i in range(N):\n",
    "        G_gamma += np.outer(stoch_score_grad_gamma[i], stoch_score_grad_gamma[i])\n",
    "    rho_gamma = eta * (G_gamma.diagonal() + eps)**(-0.5)\n",
    "\n",
    "    for k in range(K):\n",
    "        lambd[k] += np.multiply(rho_lambd, stoch_score_grad_lambd[k])\n",
    "    for i in range(N):\n",
    "        gamma[i] += np.multiply(rho_gamma, stoch_score_grad_gamma[i])\n",
    "\n",
    "    ELBO = estimate_ELBO((lambd, gamma), S)\n",
    "    ELBOs.append(ELBO)\n",
    "    if t % 100 == 0:\n",
    "        print(f\"Iteration {t}, ELBO: {ELBO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10001,) and (4640,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[633], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mELBOs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\daany\\anaconda3\\envs\\ht\\Lib\\site-packages\\matplotlib\\pyplot.py:3794\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3786\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3788\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3793\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3795\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3798\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3799\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3800\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\daany\\anaconda3\\envs\\ht\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:1779\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1779\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\daany\\anaconda3\\envs\\ht\\Lib\\site-packages\\matplotlib\\axes\\_base.py:296\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    295\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\daany\\anaconda3\\envs\\ht\\Lib\\site-packages\\matplotlib\\axes\\_base.py:486\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    483\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    490\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10001,) and (4640,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(max_iters), np.asarray(ELBOs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(1570.6642264909242), np.float64(14972.673387488474))"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = npr.RandomState(0)\n",
    "K, V, N = 10, 300, 30\n",
    "eta0, alpha0 = 0.1, 5 / K\n",
    "Ms = rs.poisson(60, size=N)\n",
    "X = generate_lda(K, V, N, Ms, eta0=eta0, alpha0=alpha0, rs_int=0)\n",
    "lambd, gamma = init_var_params(X, K, V, 0)\n",
    "beta, theta = sample_params((lambd, gamma))\n",
    "log_joint_prob((beta, theta), X), log_var_approx((lambd, gamma), (beta, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial ELBO Estimate: -13376.625584388526\n",
      "-13181.904574160842\n",
      "Iteration 0 | ELBO Estimate: -13389.404297708383\n",
      "-13445.026573833191\n",
      "-13292.946747126987\n",
      "-13351.389345770727\n",
      "-13188.608268843358\n",
      "-13456.190010973804\n",
      "-13198.820038708509\n",
      "-13424.245173566816\n",
      "-13404.460417379092\n",
      "-13495.621852282171\n",
      "-13490.112914749947\n",
      "-13313.931183301442\n",
      "-13271.125307887405\n",
      "-13271.29346346193\n",
      "-13191.668112719972\n",
      "-13297.197574788479\n",
      "-13557.120451769324\n",
      "-13600.95643203182\n",
      "-13436.01762321374\n",
      "-13200.859100119662\n",
      "-13550.396084753658\n",
      "-13536.579459945435\n",
      "-13354.433381749463\n",
      "-13272.921755892477\n",
      "-13338.574291442399\n",
      "-13502.813974590308\n",
      "-13440.31950832073\n",
      "-13600.237513304899\n",
      "-13477.700522277048\n",
      "-13310.118478619594\n",
      "-13472.119654287359\n",
      "-13433.232670427906\n",
      "-13490.51084191163\n",
      "-13321.864732287026\n",
      "-13407.701566009027\n",
      "-13487.397430774781\n",
      "-13366.225209186236\n",
      "-12986.440712734302\n",
      "-13177.682188845987\n",
      "-13414.010843302198\n",
      "-13449.431501147841\n",
      "-13461.181991411944\n",
      "-13475.193451461015\n",
      "-13208.757225930494\n",
      "-13350.70935889908\n",
      "-13386.408245802428\n",
      "-13351.572265786794\n",
      "-13247.617480263685\n",
      "-13307.819572177215\n",
      "-13554.812148634923\n",
      "-13295.79482744959\n",
      "Iteration 50 | ELBO Estimate: -13329.840980341658\n",
      "-13395.929858428073\n",
      "-13483.189417747795\n",
      "-13488.271369687145\n",
      "-13404.524192126539\n",
      "-13086.583959861931\n",
      "-13524.638667274752\n",
      "-13248.435223107903\n",
      "-13430.009741274038\n",
      "-13441.445345080236\n",
      "-13489.53144596807\n",
      "-13389.283191922572\n",
      "-13133.42270590468\n",
      "-13555.346502068745\n",
      "-13242.143995411416\n",
      "-13308.683383521728\n",
      "-13311.195146325466\n",
      "-13292.98832872297\n",
      "-13367.255162634203\n",
      "-13338.345159573239\n",
      "-13523.806531458586\n",
      "-13355.63509740055\n",
      "-13438.70273928703\n",
      "-13247.378227710926\n",
      "-13323.422104650603\n",
      "-13369.399678270933\n",
      "-13246.524348854146\n",
      "-13286.065002123487\n",
      "-13457.509060647135\n",
      "-13316.444092787266\n",
      "-13204.915528818588\n",
      "-13482.694509524756\n",
      "-13363.602788071643\n",
      "-13275.608456019492\n",
      "-13349.01281843299\n",
      "-13267.50978307406\n",
      "-13338.854117983845\n",
      "-13514.659989563594\n",
      "-13351.28256747082\n",
      "-13262.70386790036\n",
      "-13526.349541351872\n",
      "-13353.080017235097\n",
      "-13139.238374874889\n",
      "-13272.184872885584\n",
      "-13281.866482942585\n",
      "-13290.438306694648\n",
      "-13520.990471609457\n",
      "-13332.40401483227\n",
      "-13293.708824152674\n",
      "-13203.571158437724\n",
      "-13376.651237232712\n",
      "Iteration 100 | ELBO Estimate: -13346.807025648779\n",
      "-13451.873477102281\n",
      "-13228.734213106974\n",
      "-13388.771437212079\n",
      "-13328.47995052632\n",
      "-13349.660778748672\n",
      "-13705.013226089946\n",
      "-13336.860965383607\n",
      "-13379.023540202958\n",
      "-13465.162148732452\n",
      "-13121.03037974895\n",
      "-13377.8167004279\n",
      "-13474.696600740945\n",
      "-13124.79992828152\n",
      "-13426.8202990486\n",
      "-13435.771772669634\n",
      "-13272.749460396511\n",
      "-13407.069642362241\n",
      "-13569.067739268796\n",
      "-13375.00430762186\n",
      "-13409.259562717883\n",
      "-13229.067576809368\n",
      "-13211.808098137404\n",
      "-13459.580985682293\n",
      "-13436.660807099193\n",
      "-13270.700486841137\n",
      "-13270.666566307944\n",
      "-13358.819383013506\n",
      "-13329.948810004693\n",
      "-13214.431313399129\n",
      "-13455.897199057341\n",
      "-13325.845439099101\n",
      "-13393.397395753673\n",
      "-13562.04031026282\n",
      "-13335.219110155573\n",
      "-13453.286401923819\n",
      "-13391.731855651522\n",
      "-13480.090798670872\n",
      "-13330.45451912916\n",
      "-13235.530083937214\n",
      "-13307.985454138628\n",
      "-13315.030862227753\n",
      "-13393.185652002592\n",
      "-13410.717807674246\n",
      "-13365.354946705571\n",
      "-13376.65094864347\n",
      "-13312.561746533687\n",
      "-13314.402380746056\n",
      "-13337.16639271777\n",
      "-13331.408338820223\n",
      "-13432.669069183707\n",
      "Iteration 150 | ELBO Estimate: -13291.735022572053\n",
      "-13409.685845947191\n",
      "-13492.207419622571\n",
      "-13312.341313633831\n",
      "-13346.749869133773\n",
      "-13298.240121987023\n",
      "-13477.952176599\n",
      "-13419.372713935336\n",
      "-13441.20929899972\n",
      "-13350.255274837657\n",
      "-13199.829705201984\n",
      "-13451.199168329322\n",
      "-13255.016197814022\n",
      "-13388.83745228713\n",
      "-13341.97081989632\n",
      "-13151.87810979305\n",
      "-13379.640506097581\n",
      "-13252.90290947506\n",
      "-13305.110030024129\n",
      "-13496.899638612756\n",
      "-13416.911483964963\n",
      "-13404.074393801218\n",
      "-13482.327606307548\n",
      "-13357.100151215927\n",
      "-13323.30754445525\n",
      "-13322.246652856273\n",
      "-13564.831206863442\n",
      "-13246.961157280068\n",
      "-13485.666183814159\n",
      "-13350.533374703416\n",
      "-13308.658692732744\n",
      "-13380.993250763564\n",
      "-13454.644129403887\n",
      "-13611.817797777498\n",
      "-13344.221458701157\n",
      "-13560.400330318289\n",
      "-13313.323987696007\n",
      "-13291.124840598854\n",
      "-13372.83897630665\n",
      "-13543.37977125061\n",
      "-13492.934172348563\n",
      "-13238.904074524093\n",
      "-13420.808795360954\n",
      "-13393.516784456453\n",
      "-13351.10417353293\n",
      "-13417.238235691231\n",
      "-13339.120974280875\n",
      "-13382.40521282643\n",
      "-13249.949115131749\n",
      "-13555.226063983322\n",
      "-13367.83775518757\n",
      "Iteration 200 | ELBO Estimate: -13378.104728856812\n",
      "-13323.155411943808\n",
      "-13295.881341460094\n",
      "-13376.600665690266\n",
      "-13472.268173344346\n",
      "-13495.962211590728\n",
      "-13411.380914657988\n",
      "-13248.963961252124\n",
      "-13294.853998056587\n",
      "-13544.285977818328\n",
      "-13560.53992821658\n",
      "-13181.032437563532\n",
      "-13437.041684475727\n",
      "-13344.876456269498\n",
      "-13251.13098784337\n",
      "-13338.630944386578\n",
      "-13518.046973497556\n",
      "-13428.944212087934\n",
      "-13210.6639299376\n",
      "-13327.153144734224\n",
      "-13343.695122662108\n",
      "-13567.051822473111\n",
      "-13173.314167262846\n",
      "-13356.513709229937\n",
      "-13461.911013751922\n",
      "-13222.499441352207\n",
      "-13264.162533885348\n",
      "-13394.569493388592\n",
      "-13370.836991622185\n",
      "-13276.421315482567\n",
      "-13235.275745850446\n",
      "-13466.04719362571\n",
      "-13315.249229028024\n",
      "-13599.853761936438\n",
      "-13446.536332725862\n",
      "-13228.168283179013\n",
      "-13312.033624037307\n",
      "-13344.771713720862\n",
      "-13446.021361644045\n",
      "-13204.526767213742\n",
      "-13241.62001136033\n",
      "-13158.26467727441\n",
      "-13543.439701300473\n",
      "-13584.29166994512\n",
      "-13186.302631612169\n",
      "-13532.658989422522\n",
      "-13305.820116379013\n",
      "-13232.603901941158\n",
      "-13320.055644282038\n",
      "-13308.83248476564\n",
      "-13336.908001088552\n",
      "Iteration 250 | ELBO Estimate: -13381.827209734049\n",
      "-13276.288236415774\n",
      "-13331.03666758768\n",
      "-13309.146157514842\n",
      "-13479.291080063707\n",
      "-13070.486668623324\n",
      "-13087.845981279375\n",
      "-13354.336713073872\n",
      "-13366.253456261727\n",
      "-13328.77633670522\n",
      "-13236.615916710452\n",
      "-13370.530487402682\n",
      "-13564.180293254642\n",
      "-13242.224940763339\n",
      "-13136.866389346022\n",
      "-13541.934270739785\n",
      "-13488.934797559014\n",
      "-13254.143102443435\n",
      "-13451.010535031895\n",
      "-13443.574100437148\n",
      "-13256.944488801275\n",
      "-13324.12589171481\n",
      "-13316.669827750262\n",
      "-13264.672817791905\n",
      "-13345.930480372755\n",
      "-13267.207210287415\n",
      "-13188.81662537889\n",
      "-13267.305094977886\n",
      "-13386.88230607629\n",
      "-13339.107331585357\n",
      "-13314.53092285727\n",
      "-13203.317741615001\n",
      "-13321.165698223684\n",
      "-13427.694338956237\n",
      "-13358.244587973459\n",
      "-13272.579688059777\n",
      "-13389.76628338719\n",
      "-13389.168448307584\n",
      "-13381.118519541034\n",
      "-13432.727991560037\n",
      "-13166.101614827643\n",
      "-13287.324767320451\n",
      "-13390.756411488392\n",
      "-13233.26638034511\n",
      "-13423.496317766658\n",
      "-13275.032290083507\n",
      "-13526.578828352971\n",
      "-13378.305713941694\n",
      "-13470.096645256255\n",
      "-13223.749449067967\n",
      "-13247.460669647999\n",
      "Iteration 300 | ELBO Estimate: -13278.567607438308\n",
      "-13367.403178274646\n",
      "-13255.731680291203\n",
      "-13282.911304863042\n",
      "-13369.57021660044\n",
      "-13483.928830727113\n",
      "-13321.896156266732\n",
      "-13508.838839182263\n",
      "-13274.55405794602\n",
      "-13521.26538702582\n",
      "-13546.202846791242\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[595], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m ELBO_est \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(S):\n\u001b[1;32m---> 59\u001b[0m     beta_s, theta_s \u001b[38;5;241m=\u001b[39m \u001b[43msample_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     log_p \u001b[38;5;241m=\u001b[39m log_joint_prob((beta_s, theta_s), X)\n\u001b[0;32m     61\u001b[0m     log_q \u001b[38;5;241m=\u001b[39m log_var_approx((lambd, gamma), (beta_s, theta_s))\n",
      "Cell \u001b[1;32mIn[585], line 24\u001b[0m, in \u001b[0;36msample_params\u001b[1;34m(var_params)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample_params\u001b[39m(var_params):\n\u001b[0;32m     23\u001b[0m     lambd, gamma \u001b[38;5;241m=\u001b[39m var_params\n\u001b[1;32m---> 24\u001b[0m     log_gamm_beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(npr\u001b[38;5;241m.\u001b[39mgamma(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlambd\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     25\u001b[0m     log_probs_beta \u001b[38;5;241m=\u001b[39m log_gamm_beta \u001b[38;5;241m-\u001b[39m logsumexp(log_gamm_beta, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     26\u001b[0m     beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(log_probs_beta)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "S = 10\n",
    "rs = npr.RandomState(0)\n",
    "K, V, N = 10, 300, 30\n",
    "eta0, alpha0 = 0.1, 5 / K\n",
    "Ms = rs.poisson(60, size=N)\n",
    "eta = 0.00001\n",
    "eps = 1e-8\n",
    "X = generate_lda(K, V, N, Ms, eta0=0.01, alpha0=(5 / K), rs_int=0)\n",
    "lambd, gamma = init_var_params(X, K, V, 0)\n",
    "G_lambda = np.zeros((V, V))\n",
    "G_gamma = np.zeros((K, K))\n",
    "\n",
    "ELBOs = []\n",
    "ELBO_init = 0.0\n",
    "for s in range(S):\n",
    "    beta_s, theta_s = sample_params((lambd, gamma))\n",
    "    ELBO_init += log_joint_prob((beta_s, theta_s), X) - log_var_approx((lambd, gamma), (beta_s, theta_s))\n",
    "print(f\"Initial ELBO Estimate: {ELBO_init / S}\")\n",
    "ELBOs.append(ELBO_init)\n",
    "\n",
    "for t in range(501):\n",
    "    betas = []\n",
    "    thetas = []\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    for s in range(S):\n",
    "        beta_s, theta_s = sample_params((lambd, gamma))\n",
    "        grad_lambda_s, grad_gamma_s = stoch_score_grad((lambd, gamma), (beta_s, theta_s))\n",
    "        log_p, log_q = log_joint_prob((beta_s, theta_s), X), log_var_approx((lambd, gamma), (beta_s, theta_s))\n",
    "\n",
    "        grad_lambda += grad_lambda_s * (log_p - log_q)\n",
    "        grad_gamma += grad_gamma_s * (log_p - log_q)\n",
    "    grad_lambda /= S\n",
    "    grad_gamma /= S\n",
    "\n",
    "    for k in range(K):\n",
    "        G_lambda += np.outer(grad_lambda[k], grad_lambda[k])\n",
    "    rho_lambda = eta * (G_lambda.diagonal() + eps)**(-0.5)\n",
    "    lambd += rho_lambda * grad_lambda\n",
    "    for i in range(N):\n",
    "        G_gamma += np.outer(grad_gamma[i], grad_gamma[i])\n",
    "    rho_gamma = eta * (G_gamma.diagonal() + eps)**(-0.5)\n",
    "    gamma += rho_gamma * grad_gamma\n",
    "\n",
    "# G_lambda += grad_lambda * grad_lambda\n",
    "# rho_lambda = eta * (G_lambda + eps)**(-0.5)\n",
    "# lambd += rho_lambda * grad_lambda\n",
    "\n",
    "# G_gamma += grad_gamma * grad_gamma\n",
    "# rho_gamma = eta * (G_gamma + eps)**(-0.5)\n",
    "# gamma += rho_gamma * grad_gamma\n",
    "\n",
    "    ELBO_est = 0.0\n",
    "    for s in range(S):\n",
    "        beta_s, theta_s = sample_params((lambd, gamma))\n",
    "        log_p = log_joint_prob((beta_s, theta_s), X)\n",
    "        log_q = log_var_approx((lambd, gamma), (beta_s, theta_s))\n",
    "        ELBO_est += (log_p - log_q)\n",
    "    ELBOs.append(ELBO_est / S)\n",
    "    if t % 50 == 0:\n",
    "        print(f\"Iteration {t} | ELBO Estimate: {ELBO_est / S}\")\n",
    "\n",
    "plt.plot(np.arange(0, len(ELBOs)), np.asarray(ELBOs))\n",
    "# G_lambda += np.square(grad_lambda)\n",
    "# G_gamma += np.square(grad_gamma)\n",
    "# rho_lambda = rho / (np.sqrt(G_lambda) + eps)\n",
    "# rho_gamma = rho / (np.sqrt(G_gamma) + eps)\n",
    "\n",
    "# lambd += rho_lambda * grad_lambda\n",
    "# gamma += rho_gamma * grad_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Parameter vector 'a' must be one dimensional, but a.shape = ().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[512], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlog_joint_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_param_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_param_samples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[496], line 48\u001b[0m, in \u001b[0;36mlog_joint_prob\u001b[1;34m(latent_params, X)\u001b[0m\n\u001b[0;32m     45\u001b[0m K \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     46\u001b[0m N \u001b[38;5;241m=\u001b[39m theta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 48\u001b[0m log_p_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m log_p_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m.\u001b[39mlogpdf(theta[i], np\u001b[38;5;241m.\u001b[39mfull(theta[i]\u001b[38;5;241m.\u001b[39mshape, alpha0)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N))\n\u001b[0;32m     50\u001b[0m log_p_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "Cell \u001b[1;32mIn[496], line 48\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     45\u001b[0m K \u001b[38;5;241m=\u001b[39m beta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     46\u001b[0m N \u001b[38;5;241m=\u001b[39m theta\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 48\u001b[0m log_p_beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43mdir\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogpdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K))\n\u001b[0;32m     49\u001b[0m log_p_theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mdir\u001b[39m\u001b[38;5;241m.\u001b[39mlogpdf(theta[i], np\u001b[38;5;241m.\u001b[39mfull(theta[i]\u001b[38;5;241m.\u001b[39mshape, alpha0)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N))\n\u001b[0;32m     50\u001b[0m log_p_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\daany\\anaconda3\\envs\\ht\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:1675\u001b[0m, in \u001b[0;36mdirichlet_gen.logpdf\u001b[1;34m(self, x, alpha)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogpdf\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, alpha):\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Log of the Dirichlet probability density function.\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \n\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \n\u001b[0;32m   1674\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1675\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[43m_dirichlet_check_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1676\u001b[0m     x \u001b[38;5;241m=\u001b[39m _dirichlet_check_input(alpha, x)\n\u001b[0;32m   1678\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logpdf(x, alpha)\n",
      "File \u001b[1;32mc:\\Users\\daany\\anaconda3\\envs\\ht\\Lib\\site-packages\\scipy\\stats\\_multivariate.py:1456\u001b[0m, in \u001b[0;36m_dirichlet_check_parameters\u001b[1;34m(alpha)\u001b[0m\n\u001b[0;32m   1454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll parameters must be greater than 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m alpha\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter vector \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be one dimensional, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1457\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut a.shape = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malpha\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alpha\n",
      "\u001b[1;31mValueError\u001b[0m: Parameter vector 'a' must be one dimensional, but a.shape = ()."
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "log_joint_prob((latent_param_samples[0][s], latent_param_samples[1][s]), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.2087412 , 0.22285342, 0.14564812, 0.11468519, 0.3267338 ,\n",
       "        0.20175505, 0.16042344, 0.1047616 , 0.14141906, 0.19368743,\n",
       "        0.1232136 , 0.13963517, 0.35248797, 0.17897851, 0.19773441,\n",
       "        0.19807259, 0.14644993, 0.13598942, 0.17542377, 0.10784744,\n",
       "        0.10679571, 0.1076479 , 0.2741715 , 0.36743574, 0.18058184,\n",
       "        0.23407123, 0.12340706, 0.15683956, 0.18554181, 0.12700335,\n",
       "        0.10848266, 0.18291311, 0.16392528, 0.29801047, 0.46521162,\n",
       "        0.13164929, 0.23086096, 0.29104962, 0.20261528, 0.14653046,\n",
       "        0.30480206, 0.1537737 , 0.15244529, 0.10997308, 0.14881359,\n",
       "        0.18897767, 0.09994126, 0.29783775, 0.21301221, 0.13940431,\n",
       "        0.13957767, 0.35623104, 0.11586672, 0.15009526, 0.11479504,\n",
       "        0.12152344, 0.2813161 , 0.13433954, 0.22096539, 0.41937265,\n",
       "        0.12459737, 0.17136021, 0.31145371, 0.11277909, 0.13046326,\n",
       "        0.12221446, 0.13183677, 0.22212499, 0.29343044, 0.19509341,\n",
       "        0.19963806, 0.1387936 , 0.14942507, 0.15849879, 0.17303292,\n",
       "        0.10563655, 0.19086598, 0.17935589, 0.24574418, 0.14881501,\n",
       "        0.11580188, 0.10780081, 0.13794012, 0.10678613, 0.20522978,\n",
       "        0.10844158, 0.40424181, 0.30028788, 0.15784151, 0.13581667,\n",
       "        0.13823529, 0.23012614, 0.23425161, 0.21925643, 0.10047887,\n",
       "        0.11958473, 0.15785233, 0.2079654 , 0.18408496, 0.18258029,\n",
       "        0.23028161, 0.22606191, 0.13548976, 0.1942196 , 0.16673955,\n",
       "        0.13425587, 0.16130632, 0.11310735, 0.15378049, 0.1647916 ,\n",
       "        0.11802865, 0.10545831, 0.16025609, 0.38206535, 0.31289714,\n",
       "        0.21962631, 0.12724537, 0.12394545, 0.12561751, 0.15958488,\n",
       "        0.16586455, 0.26382144, 0.30503966, 0.23001425, 0.16687254,\n",
       "        0.10109644, 0.3616661 , 0.39217655, 0.12143595, 0.11665029,\n",
       "        0.2101584 , 0.12788122, 0.1380197 , 0.12023301, 0.32944107,\n",
       "        0.44900679, 0.14603495, 0.20934657, 0.10901982, 0.21538876,\n",
       "        0.15931514, 0.27005071, 0.16926657, 0.17139679, 0.34085404,\n",
       "        0.14695241, 0.1621661 , 0.12613424, 0.15452362, 0.11214273,\n",
       "        0.31189695, 0.26816795, 0.13374331, 0.20709464, 0.20639036,\n",
       "        0.18426104, 0.28327658, 0.1656655 , 0.19025494, 0.15886866,\n",
       "        0.11822168, 0.11768214, 0.14744774, 0.38632715, 0.19297367,\n",
       "        0.13398098, 0.15938272, 0.22272016, 0.35703471, 0.13879306,\n",
       "        0.26797498, 0.12108284, 0.13860318, 0.10858713, 0.16912981,\n",
       "        0.12081484, 0.16540698, 0.13665141, 0.16274205, 0.11708728,\n",
       "        0.16707026, 0.28665693, 0.15693266, 0.24055907, 0.25677801,\n",
       "        0.18934173, 0.10592514, 0.10366685, 0.1155407 , 0.15369024,\n",
       "        0.12359519, 0.11030576, 0.12992411, 0.09906891, 0.18013887,\n",
       "        0.15145237, 0.17770407, 0.25207038, 0.10071155, 0.22050295,\n",
       "        0.19474334, 0.21366595, 0.19892811, 0.21065661, 0.24964032,\n",
       "        0.14221514, 0.12846338, 0.26609127, 0.13555518, 0.19627153,\n",
       "        0.11973378, 0.17365292, 0.24280624, 0.32401732, 0.34894141,\n",
       "        0.17252625, 0.12539622, 0.13148909, 0.11496669, 0.11022597,\n",
       "        0.10862613, 0.23765265, 0.2189316 , 0.14200281, 0.21832859,\n",
       "        0.11545032, 0.12205599, 0.17635704, 0.38068762, 0.11213526,\n",
       "        0.1703938 , 0.10326843, 0.25069997, 0.13074522, 0.16272497,\n",
       "        0.16655612, 0.2842853 , 0.22820187, 0.16472333, 0.30967575,\n",
       "        0.22049023, 0.12186617, 0.11895702, 0.12533689, 0.28024322,\n",
       "        0.21363722, 0.15012258, 0.14351467, 0.16101673, 0.14372954,\n",
       "        0.13832268, 0.11340243, 0.1017632 , 0.12263288, 0.16168288,\n",
       "        0.13628193, 0.14102238, 0.33175177, 0.19816359, 0.13485609,\n",
       "        0.17006239, 0.14898323, 0.14570912, 0.35660209, 0.15868227,\n",
       "        0.2031761 , 0.11402607, 0.21468723, 0.13935134, 0.20824105,\n",
       "        0.1032335 , 0.13067059, 0.1824139 , 0.13191613, 0.21253511,\n",
       "        0.13373572, 0.21862963, 0.16516811, 0.09891614, 0.21845569,\n",
       "        0.10641197, 0.16317517, 0.102976  , 0.10057909, 0.28298705,\n",
       "        0.11275572, 0.11141949, 0.28892532, 0.18096678, 0.14726874,\n",
       "        0.10971219, 0.23694983, 0.11650823, 0.17102713, 0.17427892,\n",
       "        0.16555949, 0.33932155, 0.15380072, 0.10552942, 0.25968386]),\n",
       " array([0.13509051, 0.12063383, 0.09871486, 0.1015903 , 0.14531245,\n",
       "        0.22521446, 0.1438634 , 0.12506288, 0.18436383, 0.10584368]))"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode(np.exp(lambd))[0], mode(np.exp(gamma))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1490.0376929100237)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambd, gamma = init_var_params(X, K, V)\n",
    "beta, theta = sample_params((lambd, gamma))\n",
    "\n",
    "K = beta.shape[0]\n",
    "N = theta.shape[0]\n",
    "log_p_beta = sum(dir.logpdf(beta[k], np.full(beta[k].shape, eta0)) for k in range(K))\n",
    "log_p_theta = sum(dir.logpdf(theta[i], np.full(theta[i].shape, alpha0)) for i in range(N))\n",
    "\n",
    "etas = np.ones(V) * eta0\n",
    "gammaln(np.sum(etas)) - np.sum(gammaln(etas)) + np.sum((etas - 1) * np.log(beta[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3423.9505787750622)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_joint_prob((beta, theta), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-208753.6964655366)"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_p_x = 0.0\n",
    "for i, (theta_i, x_i) in enumerate(zip(theta, X)):\n",
    "    beta_xi = beta[:, x_i]\n",
    "    sum_word_probs = np.sum(np.log(theta_i[:, None] * beta_xi), axis=0)\n",
    "    log_p_x += np.sum(sum_word_probs)\n",
    "log_p_x + log_p_beta + log_p_theta - log_var_approx((lambd, gamma), (beta, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.txt\", \"r\") as file:\n",
    "    vocab = [line.strip() for line in file.readlines()]\n",
    "vocab_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "V = len(vocab_to_idx)\n",
    "X = []\n",
    "\n",
    "with open(\"ap.txt\", \"r\") as file:\n",
    "    raw_text = file.read()\n",
    "documents = re.findall(r\"<TEXT>\\n(.*?)\\n </TEXT\", raw_text, re.DOTALL)\n",
    "for doc in documents:\n",
    "    words = clean_text(doc)\n",
    "    if len(words) > 150:\n",
    "        X.append([vocab_to_idx[word] for word in words])\n",
    "X = [np.asarray(x_i) for x_i in X]\n",
    "N = len(X)\n",
    "Ms = [len(x_i) for x_i in X]\n",
    "K = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Iteration: 10\n",
      "Iteration: 20\n",
      "Iteration: 30\n",
      "Iteration: 40\n",
      "Iteration: 50\n",
      "Iteration: 60\n",
      "Iteration: 70\n",
      "Iteration: 80\n",
      "Iteration: 90\n",
      "Iteration: 100\n",
      "Iteration: 110\n",
      "Iteration: 120\n",
      "Iteration: 130\n",
      "Iteration: 140\n",
      "Iteration: 150\n",
      "Iteration: 160\n",
      "Iteration: 170\n",
      "Iteration: 180\n",
      "Iteration: 190\n",
      "Iteration: 200\n",
      "Iteration: 210\n",
      "Iteration: 220\n",
      "Iteration: 230\n",
      "Iteration: 240\n",
      "Iteration: 250\n",
      "Iteration: 260\n",
      "Iteration: 270\n",
      "Iteration: 280\n",
      "Iteration: 290\n",
      "Iteration: 300\n",
      "Iteration: 310\n",
      "Iteration: 320\n",
      "Iteration: 330\n",
      "Iteration: 340\n",
      "Iteration: 350\n",
      "Iteration: 360\n",
      "Iteration: 370\n",
      "Iteration: 380\n",
      "Iteration: 390\n",
      "Iteration: 400\n",
      "Iteration: 410\n",
      "Iteration: 420\n",
      "Iteration: 430\n",
      "Iteration: 440\n",
      "Iteration: 450\n",
      "Iteration: 460\n",
      "Iteration: 470\n",
      "Iteration: 480\n",
      "Iteration: 490\n",
      "Iteration: 500\n",
      "Iteration: 510\n",
      "Iteration: 520\n",
      "Iteration: 530\n",
      "Iteration: 540\n",
      "Iteration: 550\n",
      "Iteration: 560\n",
      "Iteration: 570\n",
      "Iteration: 580\n",
      "Iteration: 590\n",
      "Iteration: 600\n",
      "Iteration: 610\n",
      "Iteration: 620\n",
      "Iteration: 630\n",
      "Iteration: 640\n",
      "Iteration: 650\n",
      "Iteration: 660\n",
      "Iteration: 670\n",
      "Iteration: 680\n",
      "Iteration: 690\n",
      "Iteration: 700\n",
      "Iteration: 710\n",
      "Iteration: 720\n",
      "Iteration: 730\n",
      "Iteration: 740\n",
      "Iteration: 750\n",
      "Iteration: 760\n",
      "Iteration: 770\n",
      "Iteration: 780\n",
      "Iteration: 790\n",
      "Iteration: 800\n",
      "Iteration: 810\n",
      "Iteration: 820\n",
      "Iteration: 830\n",
      "Iteration: 840\n",
      "Iteration: 850\n",
      "Iteration: 860\n",
      "Iteration: 870\n",
      "Iteration: 880\n",
      "Iteration: 890\n",
      "Iteration: 900\n",
      "Iteration: 910\n",
      "Iteration: 920\n",
      "Iteration: 930\n",
      "Iteration: 940\n",
      "Iteration: 950\n",
      "Iteration: 960\n",
      "Iteration: 970\n",
      "Iteration: 980\n",
      "Iteration: 990\n"
     ]
    }
   ],
   "source": [
    "S = 5\n",
    "eta0, alpha0 = 0.1, 50 / K\n",
    "eta, eps = 0.1, 1e-8\n",
    "lambd, gamma = init_var_params(X, K, V)\n",
    "G_lambda = np.zeros((K, V))\n",
    "G_gamma = np.zeros((N, K))\n",
    "\n",
    "for t in range(1000):\n",
    "    grad_lambda = np.zeros_like(lambd)\n",
    "    grad_gamma = np.zeros_like(gamma)\n",
    "    for s in range(S):\n",
    "        beta_s, theta_s = sample_params((lambd, gamma))\n",
    "        grad_lambda_s, grad_gamma_s = stoch_score_grad((lambd, gamma), (beta_s, theta_s))\n",
    "        log_p, log_q = log_joint_prob((beta_s, theta_s), X), log_var_approx((lambd, gamma), (beta_s, theta_s))\n",
    "        grad_lambda += grad_lambda_s * (log_p - log_q)\n",
    "        grad_gamma += grad_gamma_s * (log_p - log_q)\n",
    "    grad_lambda /= S\n",
    "    grad_gamma /= S\n",
    "\n",
    "    G_lambda += grad_lambda * grad_lambda\n",
    "    rho_lambda = eta * (G_lambda + eps)**(-0.5)\n",
    "    lambd += rho_lambda * grad_lambda\n",
    "\n",
    "    G_gamma += grad_gamma * grad_gamma\n",
    "    rho_gamma = eta * (G_gamma + eps)**(-0.5)\n",
    "    gamma += rho_gamma * grad_gamma\n",
    "\n",
    "    if t % 10 == 0:\n",
    "        print(f\"Iteration: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Words for Each Topic:\n",
      "\n",
      "Topic 1: horse, payment, exceeded, trucks, tour, damato, sake, hiv, aspirin, export, talk, liquidated, hoyt, butcher, mary\n",
      "\n",
      "Topic 2: zieman, marching, belonging, agents, dominate, acid, reason, territorial, holiday, ultimately, rutah, evaluations, offended, unmanned, depardieu\n",
      "\n",
      "Topic 3: whos, bust, mouth, dream, recommendation, referring, chuck, detector, plunge, bcspehealth, meal, persistent, centennial, tel, mens\n",
      "\n",
      "Topic 4: delta, verify, blown, captain, israel, genuine, concluded, dyke, financial, avenue, rifle, tourism, calls, little, shows\n",
      "\n",
      "Topic 5: edgemont, nablus, targets, efforts, nonprofit, greek, omaha, severely, lopez, strategies, archer, airbus, savings, payload, rear\n",
      "\n",
      "Topic 6: explained, nun, performed, defect, furloughs, cubic, smiling, nationwide, booming, comedy, discussion, bloody, poorly, soybeans, likud\n",
      "\n",
      "Topic 7: toys, forbidden, knight, naples, colonel, checking, yuri, louis, ratified, historians, rule, sikh, maryland, pac, perfume\n",
      "\n",
      "Topic 8: wilderness, project, sheriff, review, routinely, lot, testifying, loans, eliminated, busfield, closer, complex, nebraska, complaint, refined\n",
      "\n",
      "Topic 9: ripped, brooklyn, rich, sponsoring, des, repairs, deficiency, usjapan, roosevelt, livingston, nbcs, similarities, speakers, thcentury, armed\n",
      "\n",
      "Topic 10: institutional, dtenn, households, dave, direct, cowboy, pattern, parish, ill, commissioned, narrowly, substances, estimates, georgia, insisted\n",
      "\n",
      "Topic 11: presidentelect, deadlocked, bus, signatures, pageant, april, max, chia, chatham, proposition, huge, skull, surrounding, robertsons, availability\n",
      "\n",
      "Topic 12: gibson, disciples, brokers, cents, possibly, minute, waged, simon, abuses, coffee, sixyear, portrayed, disappointing, klaus, mistakenly\n",
      "\n",
      "Topic 13: pipelines, hate, honor, ambulance, afternoon, existence, optimistic, total, spraying, quotes, meant, glasnost, duvalier, walt, secretariat\n",
      "\n",
      "Topic 14: elite, charge, investors, ideological, arrest, hale, basketball, responsible, bans, preceded, concerning, diskin, length, larry, congressman\n",
      "\n",
      "Topic 15: fairness, rumors, turbulence, blow, solutions, theyd, owed, algiers, peggy, value, ann, maintains, metric, milken, corporation\n",
      "\n",
      "Topic 16: midwest, faces, special, marble, pumped, test, halfhour, embassy, parade, stocks, amtrak, pell, revival, necessity, outcome\n",
      "\n",
      "Topic 17: defensive, definite, cool, organized, cloudy, laurel, conservation, provided, fragile, millions, nesting, marines, pork, reagans, transplant\n",
      "\n",
      "Topic 18: bucharest, knocked, nickname, everybody, meir, patmos, education, feet, noontime, shelters, loosen, universal, celebrating, mr, intelligence\n",
      "\n",
      "Topic 19: brick, mediterranean, rubin, extortion, laugh, spotlight, uruguay, manville, midwest, franc, portuguese, audiences, slides, unclear, son\n",
      "\n",
      "Topic 20: man, drill, aeroflot, undersecretary, yearold, knew, epps, considerably, oklahoma, away, substance, organized, star, rouge, filmed\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lambd_transf = np.exp(lambd)\n",
    "word_topic_probs = lambd_transf / lambd_transf.sum(axis=1, keepdims=True)\n",
    "top_words = {}\n",
    "for k in range(word_topic_probs.shape[0]):\n",
    "    top_idxs = np.argsort(word_topic_probs[k, :])[-15:][::-1]\n",
    "    top_words[k] = [vocab[v] for v in top_idxs]\n",
    "\n",
    "formatted_text = \"Top 10 Words for Each Topic:\\n\\n\"\n",
    "for topic, words in top_words.items():\n",
    "    formatted_text += f\"Topic {topic + 1}: \"\n",
    "    formatted_text += \", \".join(words) + \"\\n\\n\"\n",
    "\n",
    "print(formatted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
