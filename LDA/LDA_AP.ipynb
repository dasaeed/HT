{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from scipy.special import digamma, loggamma\n",
    "\n",
    "assert os.path.exists(\"/Users/daany/Downloads/HT/LDA/ap.txt\") and os.path.exists(\"/Users/daany/Downloads/HT/LDA/vocab.txt\")\n",
    "\n",
    "with open(\"vocab.txt\", \"r\") as f:\n",
    "    vocab = set(f.read().splitlines())\n",
    "\n",
    "with open(\"ap.txt\", \"r\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "texts = re.findall(r\"<TEXT>(.*?)</TEXT>\", raw_text, re.DOTALL)\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "documents = []\n",
    "\n",
    "for text in texts:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words and word in vocab]\n",
    "    documents.append(tokens)\n",
    "\n",
    "N = len(documents)\n",
    "V = len(vocab)\n",
    "\n",
    "doc_term_matrix = np.zeros((N, V))\n",
    "vocab_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "for doc_idx, tokens in enumerate(documents):\n",
    "    token_counts = Counter(tokens)\n",
    "    for token, count in token_counts.items():\n",
    "        if token in vocab_to_index:\n",
    "            term_idx = vocab_to_index[token]\n",
    "            doc_term_matrix[doc_idx, term_idx] = count\n",
    "\n",
    "index_to_vocab = dict((val, key) for key, val in vocab_to_index.items())\n",
    "\n",
    "nonzero_idxs = []\n",
    "for doc in doc_term_matrix:\n",
    "    nonzero_idx = np.where(doc > 0)[0]\n",
    "    nonzero_idxs.append(sorted(nonzero_idx))\n",
    "\n",
    "def init_variational_params(doc_term_matrix, K):\n",
    "    N, V = doc_term_matrix.shape # N is number of documents\n",
    "    LAMBDA = np.random.uniform(low=0.01, high=1.0, size=(K, V))\n",
    "    GAMMA = np.ones((N, K))\n",
    "    PHI = []\n",
    "    for doc in doc_term_matrix:\n",
    "        num_words_per_doc = np.sum((doc > 0).astype(\"int32\"))\n",
    "        doc_PHI = np.ones((num_words_per_doc, K))\n",
    "        doc_PHI = doc_PHI / K\n",
    "        PHI.append(doc_PHI)\n",
    "\n",
    "    return LAMBDA, GAMMA, PHI\n",
    "\n",
    "def compute_ELBO(LAMBDA, GAMMA, PHI, doc_term_matrix, nonzero_idxs, K):\n",
    "    N, V = doc_term_matrix.shape\n",
    "    ELBO = 0\n",
    "\n",
    "    E_log_p_BETA = 0\n",
    "    for k in range(K):\n",
    "        E_log_p_BETA += (ETA - 1) * np.sum(digamma(LAMBDA[k]) - digamma(np.sum(LAMBDA[k])))\n",
    "    ELBO += E_log_p_BETA\n",
    "\n",
    "    E_log_p_THETA = 0\n",
    "    for i in range(N):\n",
    "        E_log_p_THETA += (ALPHA - 1) * np.sum(digamma(GAMMA[i]) - digamma(np.sum(GAMMA[i])))\n",
    "    ELBO += E_log_p_THETA\n",
    "\n",
    "    E_q_log_p_z_x = 0\n",
    "    for i in range(N):\n",
    "        doc = doc_term_matrix[i]\n",
    "        nonzero_idx = nonzero_idxs[i]\n",
    "        corr_idx = 0\n",
    "        for idx in nonzero_idx:\n",
    "            E_q_log_p_z_x += doc[idx] * np.sum(PHI[i][corr_idx] * (digamma(GAMMA[i]) - digamma(np.sum(GAMMA[i])))) \\\n",
    "                + doc[idx] * np.sum(PHI[i][corr_idx] * (digamma(LAMBDA[:, idx]) - digamma(np.sum(LAMBDA, axis=1))))\n",
    "            corr_idx += 1\n",
    "    ELBO += E_q_log_p_z_x\n",
    "\n",
    "    E_log_q_BETA = 0\n",
    "    for k in range(K):\n",
    "        E_log_q_BETA += -loggamma(np.sum(LAMBDA[k])) + np.sum(loggamma(LAMBDA[k])) \\\n",
    "            - np.sum((LAMBDA[k] - 1) * (digamma(LAMBDA[k]) - digamma(np.sum(LAMBDA[k]))))\n",
    "    ELBO += E_log_q_BETA\n",
    "\n",
    "    E_log_q_THETA = 0\n",
    "    for i in range(N):\n",
    "        E_log_q_THETA += -loggamma(np.sum(GAMMA[i])) + np.sum(loggamma(GAMMA[i])) \\\n",
    "            - np.sum((GAMMA[i] - 1) * (digamma(GAMMA[i]) - digamma(np.sum(GAMMA[i]))))\n",
    "    ELBO += E_log_q_THETA\n",
    "\n",
    "    E_q_log_z = 0\n",
    "    for i in range(N):\n",
    "        doc = doc_term_matrix[i]\n",
    "        nonzero_idx = nonzero_idxs[i]\n",
    "        corr_idx = 0\n",
    "        for idx in nonzero_idx:\n",
    "            E_q_log_z += -doc[idx] * np.sum(PHI[i][corr_idx] * np.log(PHI[i][corr_idx]))\n",
    "            corr_idx += 1\n",
    "    ELBO += E_q_log_z\n",
    "\n",
    "    return ELBO\n",
    "\n",
    "def log_sum_exp(vec):\n",
    "    a = np.max(vec, axis=0)\n",
    "    log_sum_exp = np.log(np.sum(np.exp(vec - a))) + a\n",
    "\n",
    "    return log_sum_exp\n",
    "\n",
    "def update_variational_params(LAMBDA, GAMMA, PHI, doc_term_matrix, nonzero_idxs, K):\n",
    "    N, V = doc_term_matrix.shape\n",
    "\n",
    "    print(\"Updating PHI and GAMMA\")\n",
    "    for i in tqdm(range(N)):\n",
    "        doc = doc_term_matrix[i]\n",
    "        nonzero_idx = nonzero_idxs[i]\n",
    "        corr_idx = 0\n",
    "        for idx in nonzero_idx:\n",
    "            log_PHI_ij = np.zeros((K, ))\n",
    "            for k in range(K):\n",
    "                exponent = digamma(GAMMA[i][k]) - digamma(np.sum(GAMMA[i])) \\\n",
    "                    + digamma(LAMBDA[k][idx]) - digamma(np.sum(LAMBDA[k]))\n",
    "                log_PHI_ij[k] = exponent\n",
    "            PHI_ij = np.exp(log_PHI_ij - log_sum_exp(log_PHI_ij))\n",
    "            PHI[i][corr_idx] = PHI_ij\n",
    "            corr_idx += 1\n",
    "\n",
    "        GAMMA_i = np.zeros((K, )) + ALPHA\n",
    "        for k in range(K):\n",
    "            GAMMA_i[k] += np.sum(doc[nonzero_idx] * PHI[i][:, k])\n",
    "        GAMMA[i] = GAMMA_i\n",
    "\n",
    "    print(\"Updating LAMBDA\")\n",
    "    for k in tqdm(range(K)):\n",
    "        LAMBDA_k = np.zeros((V, )) + ETA\n",
    "        for i in range(N):\n",
    "            doc = doc_term_matrix[i]\n",
    "            nonzero_idx = nonzero_idxs[i]\n",
    "            corr_idx = 0\n",
    "            for idx in nonzero_idx:\n",
    "                LAMBDA_k[idx] += doc[idx] * PHI[i][corr_idx][k]\n",
    "                corr_idx += 1\n",
    "        LAMBDA[k] = LAMBDA_k\n",
    "\n",
    "    return LAMBDA, GAMMA, PHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Updating PHI and GAMMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:36<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating LAMBDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the ELBO for current variational parameters\n",
      "\n",
      "\n",
      "Iteration: 2\n",
      "Updating PHI and GAMMA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:22<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating LAMBDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:03<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the ELBO for current variational parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daany\\AppData\\Local\\Temp\\ipykernel_35468\\813837707.py:107: RuntimeWarning: divide by zero encountered in log\n",
      "  E_q_log_z += -doc[idx] * np.sum(PHI[i][corr_idx] * np.log(PHI[i][corr_idx]))\n",
      "C:\\Users\\daany\\AppData\\Local\\Temp\\ipykernel_35468\\813837707.py:107: RuntimeWarning: invalid value encountered in multiply\n",
      "  E_q_log_z += -doc[idx] * np.sum(PHI[i][corr_idx] * np.log(PHI[i][corr_idx]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix = doc_term_matrix[0:1000]\n",
    "ETA = 1 / V\n",
    "ALPHA = 0.1\n",
    "K = 30 \n",
    "tol = 30\n",
    "iteration = 1\n",
    "curr_ELBO = 0\n",
    "prev_ELBO = 100\n",
    "ELBOs = []\n",
    "\n",
    "start = time.time()\n",
    "LAMBDA, GAMMA, PHI = init_variational_params(doc_term_matrix, K)\n",
    "ELBOs.append(compute_ELBO(LAMBDA, GAMMA, PHI, doc_term_matrix, nonzero_idxs, K))\n",
    "while np.abs(curr_ELBO - prev_ELBO) > tol:\n",
    "    print(f\"Iteration: {iteration}\")\n",
    "    LAMBDA, GAMMA, PHI = update_variational_params(LAMBDA, GAMMA, PHI, doc_term_matrix, nonzero_idxs, K)\n",
    "    prev_ELBO = curr_ELBO\n",
    "    print(\"Computing the ELBO for current variational parameters\")\n",
    "    curr_ELBO = compute_ELBO(LAMBDA, GAMMA, PHI, doc_term_matrix, nonzero_idxs, K)\n",
    "    ELBOs.append(curr_ELBO)\n",
    "    iteration += 1\n",
    "    print(\"\\n\")\n",
    "end = time.time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
